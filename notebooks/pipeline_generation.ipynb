{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import sdv\n",
    "print(sdv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data_synthesizer.util import  plot_training_loss, ModelType\n",
    "from data_loader import DataLoader\n",
    "from data_synthesizer.sdv import SDVCTGAN_\n",
    "from data_evaluator import histo_plot_utility_compare, ClassifierType, MultivariateEvaluator, UtilityEvaluation, accuracy_compare\n",
    "from data_evaluator.privacy_evaluation import SimilarityType\n",
    "# from evaluation_report import EvaluationReportBuilder, EvaluationType, EvaluationReport\n",
    "from data_synthesizer.pipeline.evaluation_task import ResemblanceEvaluationTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list_credit_card = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6', 'default.payment.next.month']\n",
    "# cat_list_credit_card = ['EDUCATION', 'MARRIAGE', 'PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6', 'default.payment.next.month']\n",
    "num_list_credit_card = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4','BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3','PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "df_real_credit_card_train = DataLoader('../data/credit_card_Train.csv').get_dataframe(cat_list_credit_card, str, drop_identation=True)\n",
    "df_real_credit_card_test = DataLoader('../data/credit_card_Test.csv').get_dataframe(cat_list_credit_card, str, drop_identation=True)\n",
    "df_real_credit_card_ctgan_holdout = DataLoader('../data/credit_card_Test.csv').get_dataframe(cat_list_credit_card, drop_identation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list_adult = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country','income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrete_columns :  ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'default.payment.next.month']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m metadata \u001b[38;5;241m=\u001b[39m SingleTableMetadata()\n\u001b[1;32m      3\u001b[0m metadata\u001b[38;5;241m.\u001b[39mdetect_from_dataframe(data\u001b[38;5;241m=\u001b[39mdf_real_credit_card_train)\n\u001b[0;32m----> 4\u001b[0m ctgan \u001b[38;5;241m=\u001b[39m \u001b[43mSDVCTGAN_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_real_credit_card_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabularDataSynth2/tabularDataSynth/src/data_synthesizer/sdv/ctgan/ctgan_synthesizer_modified.py:44\u001b[0m, in \u001b[0;36mSDVCTGAN_.__init__\u001b[0;34m(self, metadata, data, enforce_min_max_values, enforce_rounding, locales, embedding_dim, generator_dim, discriminator_dim, generator_lr, generator_decay, discriminator_lr, discriminator_decay, batch_size, discriminator_steps, log_frequency, verbose, epochs, pac, cuda)\u001b[0m\n\u001b[1;32m     25\u001b[0m discrete_columns \u001b[38;5;241m=\u001b[39m detect_discrete_columns(metadata, data, transformers)       \n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: data,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: embedding_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete_columns\u001b[39m\u001b[38;5;124m'\u001b[39m: discrete_columns\n\u001b[1;32m     43\u001b[0m }\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mModifiedCTGAN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tabularDataSynth2/tabularDataSynth/src/data_synthesizer/sdv/ctgan/ctgan_modified.py:104\u001b[0m, in \u001b[0;36mModifiedCTGAN.__init__\u001b[0;34m(self, data, embedding_dim, generator_dim, discriminator_dim, generator_lr, generator_decay, discriminator_lr, discriminator_decay, batch_size, discriminator_steps, log_frequency, verbose, epochs, pac, cuda, discrete_columns)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer \u001b[38;5;241m=\u001b[39m DataTransformer()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete_columns : \u001b[39m\u001b[38;5;124m'\u001b[39m, discrete_columns)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39mtransform(data)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_sampler \u001b[38;5;241m=\u001b[39m DataSampler(\n\u001b[1;32m    109\u001b[0m         train_data,\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39moutput_info_list,\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_frequency)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/ctgan/data_transformer.py:108\u001b[0m, in \u001b[0;36mDataTransformer.fit\u001b[0;34m(self, raw_data, discrete_columns)\u001b[0m\n\u001b[1;32m    106\u001b[0m     column_transform_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_discrete(raw_data[[column_name]])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 108\u001b[0m     column_transform_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_continuous\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_info_list\u001b[38;5;241m.\u001b[39mappend(column_transform_info\u001b[38;5;241m.\u001b[39moutput_info)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dimensions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m column_transform_info\u001b[38;5;241m.\u001b[39moutput_dimensions\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/ctgan/data_transformer.py:54\u001b[0m, in \u001b[0;36mDataTransformer._fit_continuous\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     48\u001b[0m column_name \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m gm \u001b[38;5;241m=\u001b[39m ClusterBasedNormalizer(\n\u001b[1;32m     50\u001b[0m     missing_value_generation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_column\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     51\u001b[0m     max_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_clusters),\n\u001b[1;32m     52\u001b[0m     weight_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_weight_threshold\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 54\u001b[0m \u001b[43mgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m num_components \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(gm\u001b[38;5;241m.\u001b[39mvalid_component_indicator)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ColumnTransformInfo(\n\u001b[1;32m     58\u001b[0m     column_name\u001b[38;5;241m=\u001b[39mcolumn_name, column_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mgm,\n\u001b[1;32m     59\u001b[0m     output_info\u001b[38;5;241m=\u001b[39m[SpanInfo(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m), SpanInfo(num_components, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)],\n\u001b[1;32m     60\u001b[0m     output_dimensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m num_components)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/rdt/transformers/base.py:57\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m method_name \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_random_states(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states, method_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_random_state):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/rdt/transformers/base.py:394\u001b[0m, in \u001b[0;36mBaseTransformer.fit\u001b[0;34m(self, data, column)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_seed(data)\n\u001b[1;32m    393\u001b[0m columns_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_columns_data(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_output_columns(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/rdt/transformers/numerical.py:496\u001b[0m, in \u001b[0;36mClusterBasedNormalizer._fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    495\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bgm_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_component_indicator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bgm_transformer\u001b[38;5;241m.\u001b[39mweights_ \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_threshold\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/mixture/_base.py:181\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mThe method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    The fitted mixture.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# parameters are validated in fit_predict\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/mixture/_base.py:247\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    244\u001b[0m prev_lower_bound \u001b[38;5;241m=\u001b[39m lower_bound\n\u001b[1;32m    246\u001b[0m log_prob_norm, log_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_e_step(X)\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_resp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m lower_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n\u001b[1;32m    250\u001b[0m change \u001b[38;5;241m=\u001b[39m lower_bound \u001b[38;5;241m-\u001b[39m prev_lower_bound\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/mixture/_bayesian_mixture.py:735\u001b[0m, in \u001b[0;36mBayesianGaussianMixture._m_step\u001b[0;34m(self, X, log_resp)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"M step.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \n\u001b[1;32m    725\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m    the point of each sample in X.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    733\u001b[0m n_samples, _ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 735\u001b[0m nk, xk, sk \u001b[38;5;241m=\u001b[39m \u001b[43m_estimate_gaussian_parameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_resp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreg_covar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcovariance_type\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_weights(nk)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimate_means(nk, xk)\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/mixture/_gaussian_mixture.py:290\u001b[0m, in \u001b[0;36m_estimate_gaussian_parameters\u001b[0;34m(X, resp, reg_covar, covariance_type)\u001b[0m\n\u001b[1;32m    288\u001b[0m nk \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(resp\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39meps\n\u001b[1;32m    289\u001b[0m means \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(resp\u001b[38;5;241m.\u001b[39mT, X) \u001b[38;5;241m/\u001b[39m nk[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m--> 290\u001b[0m covariances \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_full\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtied\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_tied\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdiag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_diag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspherical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_estimate_gaussian_covariances_spherical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovariance_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreg_covar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nk, means, covariances\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/sklearn/mixture/_gaussian_mixture.py:177\u001b[0m, in \u001b[0;36m_estimate_gaussian_covariances_full\u001b[0;34m(resp, X, nk, means, reg_covar)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_components):\n\u001b[1;32m    176\u001b[0m     diff \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m-\u001b[39m means[k]\n\u001b[0;32m--> 177\u001b[0m     covariances[k] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nk[k]\n\u001b[1;32m    178\u001b[0m     covariances[k]\u001b[38;5;241m.\u001b[39mflat[:: n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reg_covar\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m covariances\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_real_credit_card_train)\n",
    "ctgan = SDVCTGAN_(metadata, df_real_credit_card_train, verbose=False, cuda=True, epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_fit from child\n",
      "got it\n"
     ]
    }
   ],
   "source": [
    "ctgan.fit(df_real_credit_card_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ctgan.sample(24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/credit_card_ctgan_test_new.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_credit_card_train = DataLoader('../data/credit_card_Train.csv').get_dataframe(cat_list_credit_card, drop_identation=True)\n",
    "df_real_credit_card_ctgan_test_new = DataLoader('../data/credit_card_ctgan_test_new.csv').get_dataframe(cat_list_credit_card)\n",
    "df_real_credit_card_ctgan_third = DataLoader('../data/credit_card_ctgan_training_third.csv').get_dataframe(cat_list_credit_card)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>24966.0</td>\n",
       "      <td>23149.0</td>\n",
       "      <td>12198.0</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>590.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>524.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185395.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-959.0</td>\n",
       "      <td>-1228.0</td>\n",
       "      <td>6834.0</td>\n",
       "      <td>6988.0</td>\n",
       "      <td>3923.0</td>\n",
       "      <td>1553.0</td>\n",
       "      <td>13647.0</td>\n",
       "      <td>11223.0</td>\n",
       "      <td>3346.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13319.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10525.0</td>\n",
       "      <td>6977.0</td>\n",
       "      <td>28702.0</td>\n",
       "      <td>4868.0</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>1808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>3036.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>264248.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>-1906.0</td>\n",
       "      <td>2440.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>8748.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355653.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>3197.0</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>-396.0</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>7963.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>8280.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>23508.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34617.0</td>\n",
       "      <td>40897.0</td>\n",
       "      <td>35440.0</td>\n",
       "      <td>3227.0</td>\n",
       "      <td>2437.0</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>2642.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>2586.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>166832.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>-867.0</td>\n",
       "      <td>-1298.0</td>\n",
       "      <td>969.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>78340.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29343.0</td>\n",
       "      <td>49329.0</td>\n",
       "      <td>54987.0</td>\n",
       "      <td>5007.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1935.0</td>\n",
       "      <td>1152.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>271732.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>4445.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>926.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>56815.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>1188.0</td>\n",
       "      <td>-849.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL SEX EDUCATION MARRIAGE  AGE PAY_0 PAY_2 PAY_3 PAY_4 PAY_5  \\\n",
       "0        10000.0   1         2        2   22     0     0     0     0     0   \n",
       "1       185395.0   2         2        2   23    -1    -1    -1    -1    -1   \n",
       "2        13319.0   1         1        2   23     0     0     0     0     0   \n",
       "3       264248.0   2         2        2   24     0     0    -1    -1    -2   \n",
       "4       355653.0   1         2        1   42    -1    -1    -1    -1    -1   \n",
       "...          ...  ..       ...      ...  ...   ...   ...   ...   ...   ...   \n",
       "23995    23508.0   1         2        2   23     2     0     0     0     0   \n",
       "23996   166832.0   1         1        1   39     1    -2    -2    -2    -2   \n",
       "23997    78340.0   1         1        2   30     0     0     0     0     0   \n",
       "23998   271732.0   2         2        1   41    -1    -1    -1    -1    -1   \n",
       "23999    56815.0   1         1        2   28     2     2     2     0    -2   \n",
       "\n",
       "       ... BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      ...   24966.0    23149.0    12198.0    1280.0    2016.0     590.0   \n",
       "1      ...    -959.0    -1228.0     6834.0    6988.0    3923.0    1553.0   \n",
       "2      ...   10525.0     6977.0    28702.0    4868.0    1332.0    1808.0   \n",
       "3      ...    2084.0    -1906.0     2440.0    1800.0    8748.0     589.0   \n",
       "4      ...    3197.0     6782.0     -396.0    1087.0    7963.0    1222.0   \n",
       "...    ...       ...        ...        ...       ...       ...       ...   \n",
       "23995  ...   34617.0    40897.0    35440.0    3227.0    2437.0    1574.0   \n",
       "23996  ...    -867.0    -1298.0      969.0       0.0       0.0     867.0   \n",
       "23997  ...   29343.0    49329.0    54987.0    5007.0    1096.0    1440.0   \n",
       "23998  ...    1747.0     4445.0      159.0       0.0     926.0     136.0   \n",
       "23999  ...    1890.0     1188.0     -849.0    1253.0     312.0     536.0   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0         636.0     437.0     524.0                           0  \n",
       "1       13647.0   11223.0    3346.0                           1  \n",
       "2           0.0     385.0    3036.0                           0  \n",
       "3          19.0       0.0     259.0                           1  \n",
       "4        8280.0     404.0       9.0                           0  \n",
       "...         ...       ...       ...                         ...  \n",
       "23995    2642.0    1849.0    2586.0                           1  \n",
       "23996       0.0      32.0      64.0                           1  \n",
       "23997    1935.0    1152.0    1728.0                           1  \n",
       "23998    3153.0      44.0     599.0                           1  \n",
       "23999       0.0       0.0       0.0                           1  \n",
       "\n",
       "[24000 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_credit_card_ctgan_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_dict = {'CTGAN new' : \n",
    "                   (df_real_credit_card_train, df_real_credit_card_ctgan_test_new),\n",
    "                    'CTGAN' :\n",
    "                   (df_real_credit_card_train, df_real_credit_card_ctgan_third),\n",
    "                   }\n",
    "\n",
    "qai_columns = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE']\n",
    "risk_column = ['PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6','default.payment.next.month']\n",
    "builder = EvaluationReportBuilder(evaluation_dict )\n",
    "# builder.with_privacy(df_real_credit_card_test, qai_columns, risk_column).with_privacy_anonymeter(df_real_credit_card_test).get_evaluation()\n",
    "# builder.with_privacy(df_real_credit_card_test, qai_columns, risk_column).get_evaluation()\n",
    "report_ress = builder.with_resemblance().build()\n",
    "# report.save('report\\\\report_resemblance_credit_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1920f679b97c4c488397d63ec78b5738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(VBox(children=(Accordion(children=(VBox(children=(HBox(children=(HTML(value='<style type=\"text/c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "report_ress.display_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list_adult = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country','income']\n",
    "\n",
    "df_real_adult_train = DataLoader('../data/adult_train.csv').get_dataframe(cat_list_adult)\n",
    "df_real_adult_test = DataLoader('../data/adult_test.csv').get_dataframe(cat_list_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrete_columns :  ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country', 'income']\n"
     ]
    }
   ],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_real_adult_train)\n",
    "ctgan = SDVCTGAN_(metadata, df_real_adult_train, verbose=False, cuda=True, epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_fit from child\n",
      "got it\n"
     ]
    }
   ],
   "source": [
    "ctgan.fit(df_real_adult_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ctgan.sample(32561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>51</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>322582</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>58</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>189213</td>\n",
       "      <td>12th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>49</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>239051</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>38</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>304390</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>30</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>331707</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1813</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29385</th>\n",
       "      <td>32</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>298845</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29710</th>\n",
       "      <td>32</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>151602</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29951</th>\n",
       "      <td>61</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>46856</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31160</th>\n",
       "      <td>47</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>188701</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>4060</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31541</th>\n",
       "      <td>58</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>320923</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Armed-Forces</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>1852</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt      education  education-num  \\\n",
       "316     51   Federal-gov  322582        HS-grad              9   \n",
       "1539    58   Federal-gov  189213           12th              7   \n",
       "2221    49   Federal-gov  239051      Bachelors             13   \n",
       "2392    38   Federal-gov  304390        HS-grad              9   \n",
       "2737    30   Federal-gov  331707     Assoc-acdm             12   \n",
       "...    ...           ...     ...            ...            ...   \n",
       "29385   32   Federal-gov  298845      Bachelors             13   \n",
       "29710   32   Federal-gov  151602   Some-college             10   \n",
       "29951   61   Federal-gov   46856        Masters             14   \n",
       "31160   47   Federal-gov  188701   Some-college             10   \n",
       "31541   58   Federal-gov  320923      Bachelors             13   \n",
       "\n",
       "            marital-status     occupation    relationship    race    sex  \\\n",
       "316     Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "1539    Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "2221    Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "2392    Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "2737    Married-civ-spouse   Armed-Forces         Husband   Black   Male   \n",
       "...                    ...            ...             ...     ...    ...   \n",
       "29385   Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "29710   Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "29951   Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "31160        Never-married   Armed-Forces   Not-in-family   Black   Male   \n",
       "31541   Married-civ-spouse   Armed-Forces         Husband   White   Male   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "316               8             0              40   United-States   <=50K  \n",
       "1539             14             0              40   United-States   <=50K  \n",
       "2221              0             0              40   United-States   <=50K  \n",
       "2392             23             0              40   United-States   <=50K  \n",
       "2737              0          1813              40   United-States    >50K  \n",
       "...             ...           ...             ...             ...     ...  \n",
       "29385             2             0              40   United-States   <=50K  \n",
       "29710            14             0              40   United-States   <=50K  \n",
       "29951             0             0              40   United-States    >50K  \n",
       "31160          4060             0              40   United-States   <=50K  \n",
       "31541          7688          1852              40   United-States    >50K  \n",
       "\n",
       "[71 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['occupation'] == ' Armed-Forces']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/adult_ctgan_test_new.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ctgan cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list_cardio = ['gender','cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "\n",
    "df_real_cardio_train = DataLoader('../data/cardio_train.csv').get_dataframe(cat_list_cardio, category_type=str, sep = ',')\n",
    "df_real_cardio_test = DataLoader('../data/cardio_test.csv').get_dataframe(cat_list_cardio, category_type=str, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discrete_columns :  ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n"
     ]
    }
   ],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_real_cardio_train)\n",
    "ctgan = SDVCTGAN_(metadata, df_real_cardio_train, verbose=False, cuda=True, epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_fit from child\n",
      "got it\n"
     ]
    }
   ],
   "source": [
    "ctgan.fit(df_real_cardio_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ctgan.sample(49000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/cardio_ctgan_test_new.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Pipeline with Cardio - TVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "# from data_synthesizer.util import  plot_training_loss, ModelType\n",
    "from data_loader import DataLoader\n",
    "from data_synthesizer.sdv import SDVCTGAN_, SDVTVAE_\n",
    "from data_evaluator import histo_plot_utility_compare, ClassifierType, MultivariateEvaluator, UtilityEvaluation, accuracy_compare, UnivariateEvaluator\n",
    "from data_evaluator.privacy_evaluation import SimilarityType\n",
    "# from evaluation_report import EvaluationReportBuilder, EvaluationType, EvaluationReport\n",
    "from data_synthesizer.pipeline import PipelineBuilder, TaskType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list_credit_card = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6', 'default.payment.next.month']\n",
    "# cat_list_credit_card = ['EDUCATION', 'MARRIAGE', 'PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6', 'default.payment.next.month']\n",
    "num_list_credit_card = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4','BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3','PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "cat_list_adult = ['workclass','education','marital-status','occupation','relationship','race','sex','native-country','income']\n",
    "num_list_adult = ['age','fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "df_real_credit_card_train = DataLoader('../data/credit_card_Train.csv').get_dataframe(cat_list_credit_card, str, drop_identation=True)\n",
    "df_real_credit_card_test = DataLoader('../data/credit_card_Test.csv').get_dataframe(cat_list_credit_card, str, drop_identation=True)\n",
    "df_real_credit_card_ctgan_fourth = DataLoader('../data/credit_card_ctgan_training_fourth.csv').get_dataframe(cat_list_credit_card, str)\n",
    "df_real_adult_train = DataLoader('../data/adult_train.csv').get_dataframe(cat_list_adult, str)\n",
    "df_real_adult_test = DataLoader('../data/adult_test.csv').get_dataframe(cat_list_adult, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import SingleTableMetadata\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_real_adult_train)\n",
    "ctgan = SDVTVAE_(metadata, df_real_adult_train, epochs= 300, cuda=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation processing:\n",
      "Epoch 1, Reconstruct Loss:  23.7941,KLD Loss:  0.0878\n",
      "Epoch 2, Reconstruct Loss:  20.1246,KLD Loss:  0.5573\n",
      "Epoch 3, Reconstruct Loss:  16.4468,KLD Loss:  1.0638\n",
      "Epoch 4, Reconstruct Loss:  18.7770,KLD Loss:  1.5021\n",
      "Epoch 5, Reconstruct Loss:  15.1458,KLD Loss:  2.3038\n",
      "Epoch 6, Reconstruct Loss:  16.7394,KLD Loss:  2.6371\n",
      "Epoch 7, Reconstruct Loss:  13.2767,KLD Loss:  3.6936\n",
      "Epoch 8, Reconstruct Loss:  12.5327,KLD Loss:  4.9614\n",
      "Epoch 9, Reconstruct Loss:  10.5303,KLD Loss:  4.1699\n",
      "Epoch 10, Reconstruct Loss:  7.0933,KLD Loss:  4.7018\n",
      "Epoch 11, Reconstruct Loss:  9.6469,KLD Loss:  5.4988\n",
      "Epoch 12, Reconstruct Loss:  8.0385,KLD Loss:  5.4767\n",
      "Epoch 13, Reconstruct Loss:  5.6011,KLD Loss:  7.5573\n",
      "Epoch 14, Reconstruct Loss:  4.5499,KLD Loss:  6.7569\n",
      "Epoch 15, Reconstruct Loss:  3.5194,KLD Loss:  7.5395\n",
      "Epoch 16, Reconstruct Loss:  1.7619,KLD Loss:  6.7587\n",
      "Epoch 17, Reconstruct Loss:  3.4459,KLD Loss:  8.0093\n",
      "Epoch 18, Reconstruct Loss: -1.4448,KLD Loss:  7.7408\n",
      "Epoch 19, Reconstruct Loss: -1.9422,KLD Loss:  7.9854\n",
      "Epoch 20, Reconstruct Loss: -1.6683,KLD Loss:  10.0538\n",
      "Epoch 21, Reconstruct Loss: -3.8253,KLD Loss:  8.7864\n",
      "Epoch 22, Reconstruct Loss: -2.6269,KLD Loss:  9.6488\n",
      "Epoch 23, Reconstruct Loss: -4.7969,KLD Loss:  9.7280\n",
      "Epoch 24, Reconstruct Loss: -6.8473,KLD Loss:  10.4365\n",
      "Epoch 25, Reconstruct Loss: -6.8462,KLD Loss:  11.5887\n",
      "Epoch 26, Reconstruct Loss: -8.0277,KLD Loss:  11.2235\n",
      "Epoch 27, Reconstruct Loss: -6.3034,KLD Loss:  10.4550\n",
      "Epoch 28, Reconstruct Loss: -8.6914,KLD Loss:  10.5732\n",
      "Epoch 29, Reconstruct Loss: -8.4320,KLD Loss:  10.5221\n",
      "Epoch 30, Reconstruct Loss: -6.9803,KLD Loss:  11.4111\n",
      "Epoch 31, Reconstruct Loss: -4.4565,KLD Loss:  11.5835\n",
      "Epoch 32, Reconstruct Loss: -8.8975,KLD Loss:  11.1035\n",
      "Epoch 33, Reconstruct Loss: -9.4854,KLD Loss:  11.1088\n",
      "Epoch 34, Reconstruct Loss: -11.6822,KLD Loss:  11.6448\n",
      "Epoch 35, Reconstruct Loss: -9.6154,KLD Loss:  11.7798\n",
      "Epoch 36, Reconstruct Loss: -12.4317,KLD Loss:  12.8113\n",
      "Epoch 37, Reconstruct Loss: -11.0307,KLD Loss:  11.2708\n",
      "Epoch 38, Reconstruct Loss: -11.5483,KLD Loss:  11.1970\n",
      "Epoch 39, Reconstruct Loss: -7.6981,KLD Loss:  11.3370\n",
      "Epoch 40, Reconstruct Loss: -13.3897,KLD Loss:  11.9145\n",
      "Epoch 41, Reconstruct Loss: -6.8218,KLD Loss:  11.4888\n",
      "Epoch 42, Reconstruct Loss: -14.3950,KLD Loss:  11.2618\n",
      "Epoch 43, Reconstruct Loss: -8.1120,KLD Loss:  11.6116\n",
      "Epoch 44, Reconstruct Loss: -6.2167,KLD Loss:  12.4962\n",
      "Epoch 45, Reconstruct Loss: -10.7756,KLD Loss:  13.7702\n",
      "Epoch 46, Reconstruct Loss: -13.0305,KLD Loss:  12.5281\n",
      "Epoch 47, Reconstruct Loss: -13.3789,KLD Loss:  10.9482\n",
      "Epoch 48, Reconstruct Loss: -12.7656,KLD Loss:  13.1818\n",
      "Epoch 49, Reconstruct Loss: -11.6078,KLD Loss:  13.1674\n",
      "Epoch 50, Reconstruct Loss: -14.6667,KLD Loss:  12.6646\n",
      "Epoch 51, Reconstruct Loss: -13.3535,KLD Loss:  13.8106\n",
      "Epoch 52, Reconstruct Loss: -8.8335,KLD Loss:  13.9289\n",
      "Epoch 53, Reconstruct Loss: -11.5107,KLD Loss:  13.4323\n",
      "Epoch 54, Reconstruct Loss: -14.2518,KLD Loss:  12.7221\n",
      "Epoch 55, Reconstruct Loss: -8.8176,KLD Loss:  13.5855\n",
      "Epoch 56, Reconstruct Loss: -14.4609,KLD Loss:  12.8418\n",
      "Epoch 57, Reconstruct Loss: -10.9270,KLD Loss:  13.9950\n",
      "Epoch 58, Reconstruct Loss: -14.3810,KLD Loss:  13.4400\n",
      "Epoch 59, Reconstruct Loss: -11.3796,KLD Loss:  13.7205\n",
      "Epoch 60, Reconstruct Loss: -15.6827,KLD Loss:  13.9444\n",
      "Epoch 61, Reconstruct Loss: -11.1329,KLD Loss:  13.3201\n",
      "Epoch 62, Reconstruct Loss: -16.8934,KLD Loss:  13.1959\n",
      "Epoch 63, Reconstruct Loss: -7.7964,KLD Loss:  19.4052\n",
      "Epoch 64, Reconstruct Loss: -13.5978,KLD Loss:  12.8266\n",
      "Epoch 65, Reconstruct Loss: -16.6459,KLD Loss:  14.9992\n",
      "Epoch 66, Reconstruct Loss: -16.4740,KLD Loss:  15.2908\n",
      "Epoch 67, Reconstruct Loss: -2.3207,KLD Loss:  15.4967\n",
      "Epoch 68, Reconstruct Loss: -17.0236,KLD Loss:  13.3794\n",
      "Epoch 69, Reconstruct Loss: -13.7095,KLD Loss:  12.8562\n",
      "Epoch 70, Reconstruct Loss: -13.9886,KLD Loss:  14.4866\n",
      "Epoch 71, Reconstruct Loss: -20.4010,KLD Loss:  15.3632\n",
      "Epoch 72, Reconstruct Loss: -18.2678,KLD Loss:  13.9145\n",
      "Epoch 73, Reconstruct Loss: -15.4016,KLD Loss:  12.8684\n",
      "Epoch 74, Reconstruct Loss: -14.8841,KLD Loss:  13.0366\n",
      "Epoch 75, Reconstruct Loss: -15.8761,KLD Loss:  13.3605\n",
      "Epoch 76, Reconstruct Loss: -17.8130,KLD Loss:  13.7880\n",
      "Epoch 77, Reconstruct Loss: -17.4511,KLD Loss:  14.5846\n",
      "Epoch 78, Reconstruct Loss: -20.3542,KLD Loss:  14.2012\n",
      "Epoch 79, Reconstruct Loss: -18.7925,KLD Loss:  13.8702\n",
      "Epoch 80, Reconstruct Loss: -19.6979,KLD Loss:  14.1531\n",
      "Epoch 81, Reconstruct Loss: -21.7005,KLD Loss:  14.6446\n",
      "Epoch 82, Reconstruct Loss: -18.3584,KLD Loss:  14.0729\n",
      "Epoch 83, Reconstruct Loss: -18.3540,KLD Loss:  14.2925\n",
      "Epoch 84, Reconstruct Loss: -20.0194,KLD Loss:  15.3540\n",
      "Epoch 85, Reconstruct Loss: -19.9424,KLD Loss:  14.7579\n",
      "Epoch 86, Reconstruct Loss: -18.9192,KLD Loss:  13.9304\n",
      "Epoch 87, Reconstruct Loss: -20.3125,KLD Loss:  15.1936\n",
      "Epoch 88, Reconstruct Loss:  2.6781,KLD Loss:  15.3048\n",
      "Epoch 89, Reconstruct Loss: -15.1102,KLD Loss:  14.6324\n",
      "Epoch 90, Reconstruct Loss: -16.5734,KLD Loss:  13.8605\n",
      "Epoch 91, Reconstruct Loss: -18.6632,KLD Loss:  14.2367\n",
      "Epoch 92, Reconstruct Loss: -18.4444,KLD Loss:  14.9635\n",
      "Epoch 93, Reconstruct Loss: -20.4903,KLD Loss:  15.2445\n",
      "Epoch 94, Reconstruct Loss: -20.6782,KLD Loss:  14.5226\n",
      "Epoch 95, Reconstruct Loss: -13.4081,KLD Loss:  15.0106\n",
      "Epoch 96, Reconstruct Loss: -17.0482,KLD Loss:  13.4684\n",
      "Epoch 97, Reconstruct Loss: -18.6082,KLD Loss:  14.8926\n",
      "Epoch 98, Reconstruct Loss: -17.1091,KLD Loss:  15.5268\n",
      "Epoch 99, Reconstruct Loss: -19.0886,KLD Loss:  13.9047\n",
      "Epoch 100, Reconstruct Loss: -21.2696,KLD Loss:  13.8151\n",
      "Epoch 101, Reconstruct Loss: -21.8171,KLD Loss:  14.9618\n",
      "Epoch 102, Reconstruct Loss: -21.4941,KLD Loss:  13.4054\n",
      "Epoch 103, Reconstruct Loss: -18.1827,KLD Loss:  14.4350\n",
      "Epoch 104, Reconstruct Loss: -20.6089,KLD Loss:  14.8716\n",
      "Epoch 105, Reconstruct Loss: -22.3740,KLD Loss:  14.6635\n",
      "Epoch 106, Reconstruct Loss: -21.6628,KLD Loss:  15.3216\n",
      "Epoch 107, Reconstruct Loss: -21.6178,KLD Loss:  14.5100\n",
      "Epoch 108, Reconstruct Loss: -22.6681,KLD Loss:  15.5526\n",
      "Epoch 109, Reconstruct Loss: -19.9810,KLD Loss:  14.3943\n",
      "Epoch 110, Reconstruct Loss: -21.4354,KLD Loss:  14.7622\n",
      "Epoch 111, Reconstruct Loss: -15.8089,KLD Loss:  15.3398\n",
      "Epoch 112, Reconstruct Loss: -19.0863,KLD Loss:  14.6349\n",
      "Epoch 113, Reconstruct Loss: -11.5906,KLD Loss:  15.2793\n",
      "Epoch 114, Reconstruct Loss: -19.2561,KLD Loss:  16.0511\n",
      "Epoch 115, Reconstruct Loss: -9.8122,KLD Loss:  16.8701\n",
      "Epoch 116, Reconstruct Loss: -22.0621,KLD Loss:  14.8008\n",
      "Epoch 117, Reconstruct Loss: -22.4498,KLD Loss:  15.3001\n",
      "Epoch 118, Reconstruct Loss: -21.9663,KLD Loss:  15.1607\n",
      "Epoch 119, Reconstruct Loss: -21.5307,KLD Loss:  14.8730\n",
      "Epoch 120, Reconstruct Loss: -20.7849,KLD Loss:  15.2373\n",
      "Epoch 121, Reconstruct Loss: -20.5528,KLD Loss:  15.4105\n",
      "Epoch 122, Reconstruct Loss: -17.3564,KLD Loss:  15.2012\n",
      "Epoch 123, Reconstruct Loss: -23.4600,KLD Loss:  16.2924\n",
      "Epoch 124, Reconstruct Loss: -17.5503,KLD Loss:  14.7323\n",
      "Epoch 125, Reconstruct Loss: -23.0861,KLD Loss:  15.6415\n",
      "Epoch 126, Reconstruct Loss: -17.3184,KLD Loss:  15.2043\n",
      "Epoch 127, Reconstruct Loss: -18.3511,KLD Loss:  16.1434\n",
      "Epoch 128, Reconstruct Loss: -23.0091,KLD Loss:  15.1881\n",
      "Epoch 129, Reconstruct Loss: -21.0152,KLD Loss:  14.0892\n",
      "Epoch 130, Reconstruct Loss: -21.9942,KLD Loss:  15.1697\n",
      "Epoch 131, Reconstruct Loss: -20.5524,KLD Loss:  15.1424\n",
      "Epoch 132, Reconstruct Loss: -19.7262,KLD Loss:  14.9299\n",
      "Epoch 133, Reconstruct Loss: -17.2818,KLD Loss:  15.6386\n",
      "Epoch 134, Reconstruct Loss: -21.7513,KLD Loss:  14.7796\n",
      "Epoch 135, Reconstruct Loss: -24.0790,KLD Loss:  15.9053\n",
      "Epoch 136, Reconstruct Loss: -22.0042,KLD Loss:  14.3655\n",
      "Epoch 137, Reconstruct Loss: -20.6929,KLD Loss:  14.3645\n",
      "Epoch 138, Reconstruct Loss: -20.8131,KLD Loss:  17.0734\n",
      "Epoch 139, Reconstruct Loss: -22.9363,KLD Loss:  15.5151\n",
      "Epoch 140, Reconstruct Loss: -22.2662,KLD Loss:  16.2316\n",
      "Epoch 141, Reconstruct Loss: -23.9255,KLD Loss:  17.3075\n",
      "Epoch 142, Reconstruct Loss: -17.5900,KLD Loss:  16.9946\n",
      "Epoch 143, Reconstruct Loss: -24.5912,KLD Loss:  16.6204\n",
      "Epoch 144, Reconstruct Loss: -19.5313,KLD Loss:  14.9477\n",
      "Epoch 145, Reconstruct Loss: -25.8521,KLD Loss:  15.4226\n",
      "Epoch 146, Reconstruct Loss: -21.2058,KLD Loss:  14.7076\n",
      "Epoch 147, Reconstruct Loss: -19.6057,KLD Loss:  16.1609\n",
      "Epoch 148, Reconstruct Loss: -20.9590,KLD Loss:  16.3672\n",
      "Epoch 149, Reconstruct Loss: -18.5513,KLD Loss:  14.3951\n",
      "Epoch 150, Reconstruct Loss: -20.8895,KLD Loss:  13.8122\n",
      "Epoch 151, Reconstruct Loss: -22.8616,KLD Loss:  14.5268\n",
      "Epoch 152, Reconstruct Loss: -23.1430,KLD Loss:  15.1247\n",
      "Epoch 153, Reconstruct Loss: -22.2146,KLD Loss:  18.0644\n",
      "Epoch 154, Reconstruct Loss: -22.3601,KLD Loss:  14.6310\n",
      "Epoch 155, Reconstruct Loss: -23.5079,KLD Loss:  16.8003\n",
      "Epoch 156, Reconstruct Loss: -12.5917,KLD Loss:  15.4622\n",
      "Epoch 157, Reconstruct Loss: -21.9630,KLD Loss:  15.7129\n",
      "Epoch 158, Reconstruct Loss: -22.8055,KLD Loss:  16.1790\n",
      "Epoch 159, Reconstruct Loss: -21.5482,KLD Loss:  15.3325\n",
      "Epoch 160, Reconstruct Loss: -11.7194,KLD Loss:  15.3751\n",
      "Epoch 161, Reconstruct Loss: -22.5114,KLD Loss:  14.5594\n",
      "Epoch 162, Reconstruct Loss: -23.6071,KLD Loss:  14.4740\n",
      "Epoch 163, Reconstruct Loss: -24.2265,KLD Loss:  14.8912\n",
      "Epoch 164, Reconstruct Loss: -21.3864,KLD Loss:  15.3798\n",
      "Epoch 165, Reconstruct Loss: -22.3232,KLD Loss:  14.9986\n",
      "Epoch 166, Reconstruct Loss: -21.1072,KLD Loss:  15.3269\n",
      "Epoch 167, Reconstruct Loss: -21.0487,KLD Loss:  15.7721\n",
      "Epoch 168, Reconstruct Loss: -22.0742,KLD Loss:  15.5367\n",
      "Epoch 169, Reconstruct Loss: -23.1359,KLD Loss:  16.2532\n",
      "Epoch 170, Reconstruct Loss: -24.7353,KLD Loss:  14.0126\n",
      "Epoch 171, Reconstruct Loss: -24.4600,KLD Loss:  15.0224\n",
      "Epoch 172, Reconstruct Loss: -21.7215,KLD Loss:  16.0108\n",
      "Epoch 173, Reconstruct Loss: -25.3993,KLD Loss:  16.0623\n",
      "Epoch 174, Reconstruct Loss: -24.6639,KLD Loss:  15.4216\n",
      "Epoch 175, Reconstruct Loss: -23.4024,KLD Loss:  16.0397\n",
      "Epoch 176, Reconstruct Loss: -26.3105,KLD Loss:  17.0232\n",
      "Epoch 177, Reconstruct Loss: -26.3353,KLD Loss:  16.8462\n",
      "Epoch 178, Reconstruct Loss: -27.9772,KLD Loss:  15.1531\n",
      "Epoch 179, Reconstruct Loss: -27.2503,KLD Loss:  15.4900\n",
      "Epoch 180, Reconstruct Loss: -25.5150,KLD Loss:  15.2772\n",
      "Epoch 181, Reconstruct Loss: -24.4445,KLD Loss:  18.1487\n",
      "Epoch 182, Reconstruct Loss: -28.6082,KLD Loss:  16.2350\n",
      "Epoch 183, Reconstruct Loss: -27.6707,KLD Loss:  16.4886\n",
      "Epoch 184, Reconstruct Loss: -24.5471,KLD Loss:  15.5145\n",
      "Epoch 185, Reconstruct Loss: -26.4424,KLD Loss:  15.6456\n",
      "Epoch 186, Reconstruct Loss: -27.3038,KLD Loss:  16.3202\n",
      "Epoch 187, Reconstruct Loss: -24.8206,KLD Loss:  14.7104\n",
      "Epoch 188, Reconstruct Loss: -25.8055,KLD Loss:  16.0786\n",
      "Epoch 189, Reconstruct Loss: -25.5823,KLD Loss:  16.3338\n",
      "Epoch 190, Reconstruct Loss: -27.0599,KLD Loss:  15.3219\n",
      "Epoch 191, Reconstruct Loss: -24.7101,KLD Loss:  18.6963\n",
      "Epoch 192, Reconstruct Loss: -28.5195,KLD Loss:  17.0309\n",
      "Epoch 193, Reconstruct Loss: -28.8056,KLD Loss:  15.8395\n",
      "Epoch 194, Reconstruct Loss: -19.6418,KLD Loss:  16.6730\n",
      "Epoch 195, Reconstruct Loss: -26.4112,KLD Loss:  15.7189\n",
      "Epoch 196, Reconstruct Loss: -24.0910,KLD Loss:  15.3609\n",
      "Epoch 197, Reconstruct Loss: -25.8329,KLD Loss:  14.2409\n",
      "Epoch 198, Reconstruct Loss: -24.5529,KLD Loss:  16.6082\n",
      "Epoch 199, Reconstruct Loss: -25.7564,KLD Loss:  15.4347\n",
      "Epoch 200, Reconstruct Loss: -23.7787,KLD Loss:  14.6962\n",
      "Epoch 201, Reconstruct Loss: -25.9651,KLD Loss:  14.5329\n",
      "Epoch 202, Reconstruct Loss: -26.1785,KLD Loss:  17.2553\n",
      "Epoch 203, Reconstruct Loss: -26.5711,KLD Loss:  16.7772\n",
      "Epoch 204, Reconstruct Loss: -26.7571,KLD Loss:  16.3270\n",
      "Epoch 205, Reconstruct Loss: -26.9593,KLD Loss:  17.4857\n",
      "Epoch 206, Reconstruct Loss: -25.9975,KLD Loss:  16.9498\n",
      "Epoch 207, Reconstruct Loss: -28.6507,KLD Loss:  15.7565\n",
      "Epoch 208, Reconstruct Loss: -27.3485,KLD Loss:  16.8638\n",
      "Epoch 209, Reconstruct Loss: -27.6441,KLD Loss:  17.0103\n",
      "Epoch 210, Reconstruct Loss: -24.7879,KLD Loss:  16.3390\n",
      "Epoch 211, Reconstruct Loss: -30.0761,KLD Loss:  17.4820\n",
      "Epoch 212, Reconstruct Loss: -27.3354,KLD Loss:  16.4227\n",
      "Epoch 213, Reconstruct Loss: -26.7206,KLD Loss:  17.1857\n",
      "Epoch 214, Reconstruct Loss: -27.2190,KLD Loss:  16.1549\n",
      "Epoch 215, Reconstruct Loss: -29.0794,KLD Loss:  17.4330\n",
      "Epoch 216, Reconstruct Loss: -28.2828,KLD Loss:  16.9706\n",
      "Epoch 217, Reconstruct Loss: -28.4136,KLD Loss:  16.4118\n",
      "Epoch 218, Reconstruct Loss: -28.5583,KLD Loss:  17.0593\n",
      "Epoch 219, Reconstruct Loss: -26.4458,KLD Loss:  14.5712\n",
      "Epoch 220, Reconstruct Loss: -28.3608,KLD Loss:  15.0999\n",
      "Epoch 221, Reconstruct Loss: -18.0474,KLD Loss:  17.6421\n",
      "Epoch 222, Reconstruct Loss: -27.3927,KLD Loss:  15.4306\n",
      "Epoch 223, Reconstruct Loss: -28.0894,KLD Loss:  15.3489\n",
      "Epoch 224, Reconstruct Loss: -27.7132,KLD Loss:  17.1132\n",
      "Epoch 225, Reconstruct Loss: -25.7665,KLD Loss:  17.0145\n",
      "Epoch 226, Reconstruct Loss: -27.3406,KLD Loss:  16.2534\n",
      "Epoch 227, Reconstruct Loss: -28.7041,KLD Loss:  16.0096\n",
      "Epoch 228, Reconstruct Loss: -28.9514,KLD Loss:  15.9004\n",
      "Epoch 229, Reconstruct Loss: -25.0284,KLD Loss:  17.4232\n",
      "Epoch 230, Reconstruct Loss: -26.0307,KLD Loss:  16.1960\n",
      "Epoch 231, Reconstruct Loss: -25.5156,KLD Loss:  17.3595\n",
      "Epoch 232, Reconstruct Loss: -25.6041,KLD Loss:  16.0125\n",
      "Epoch 233, Reconstruct Loss: -25.5735,KLD Loss:  16.0303\n",
      "Epoch 234, Reconstruct Loss: -25.4097,KLD Loss:  15.7789\n",
      "Epoch 235, Reconstruct Loss: -27.6185,KLD Loss:  16.0194\n",
      "Epoch 236, Reconstruct Loss: -27.6697,KLD Loss:  15.9135\n",
      "Epoch 237, Reconstruct Loss: -29.6368,KLD Loss:  15.9613\n",
      "Epoch 238, Reconstruct Loss: -28.0287,KLD Loss:  15.4158\n",
      "Epoch 239, Reconstruct Loss: -14.8151,KLD Loss:  16.3524\n",
      "Epoch 240, Reconstruct Loss: -24.0710,KLD Loss:  17.3003\n",
      "Epoch 241, Reconstruct Loss: -29.5278,KLD Loss:  16.5082\n",
      "Epoch 242, Reconstruct Loss: -30.2913,KLD Loss:  16.6837\n",
      "Epoch 243, Reconstruct Loss: -27.9426,KLD Loss:  17.9492\n",
      "Epoch 244, Reconstruct Loss: -31.6053,KLD Loss:  16.5415\n",
      "Epoch 245, Reconstruct Loss: -26.1125,KLD Loss:  17.1984\n",
      "Epoch 246, Reconstruct Loss: -27.6143,KLD Loss:  16.4662\n",
      "Epoch 247, Reconstruct Loss: -27.1258,KLD Loss:  17.7638\n",
      "Epoch 248, Reconstruct Loss: -27.3965,KLD Loss:  16.4378\n",
      "Epoch 249, Reconstruct Loss: -26.8596,KLD Loss:  18.5740\n",
      "Epoch 250, Reconstruct Loss: -30.4936,KLD Loss:  16.0225\n",
      "Epoch 251, Reconstruct Loss: -31.0663,KLD Loss:  16.4821\n",
      "Epoch 252, Reconstruct Loss: -27.5574,KLD Loss:  16.6212\n",
      "Epoch 253, Reconstruct Loss: -27.3749,KLD Loss:  16.6598\n",
      "Epoch 254, Reconstruct Loss: -30.2182,KLD Loss:  16.9724\n",
      "Epoch 255, Reconstruct Loss: -31.3129,KLD Loss:  16.3929\n",
      "Epoch 256, Reconstruct Loss: -31.5407,KLD Loss:  16.4894\n",
      "Epoch 257, Reconstruct Loss: -28.7204,KLD Loss:  15.6735\n",
      "Epoch 258, Reconstruct Loss: -29.6782,KLD Loss:  16.8565\n",
      "Epoch 259, Reconstruct Loss: -28.5902,KLD Loss:  17.2782\n",
      "Epoch 260, Reconstruct Loss: -28.4545,KLD Loss:  17.0981\n",
      "Epoch 261, Reconstruct Loss: -27.8397,KLD Loss:  18.3249\n",
      "Epoch 262, Reconstruct Loss: -27.7171,KLD Loss:  17.3822\n",
      "Epoch 263, Reconstruct Loss: -28.7463,KLD Loss:  16.5303\n",
      "Epoch 264, Reconstruct Loss: -29.2322,KLD Loss:  16.0791\n",
      "Epoch 265, Reconstruct Loss: -30.9553,KLD Loss:  16.9460\n",
      "Epoch 266, Reconstruct Loss: -28.7672,KLD Loss:  16.5356\n",
      "Epoch 267, Reconstruct Loss: -29.8925,KLD Loss:  17.4344\n",
      "Epoch 268, Reconstruct Loss: -28.2326,KLD Loss:  17.0011\n",
      "Epoch 269, Reconstruct Loss: -29.5776,KLD Loss:  16.5576\n",
      "Epoch 270, Reconstruct Loss: -28.1689,KLD Loss:  19.1940\n",
      "Epoch 271, Reconstruct Loss: -29.0930,KLD Loss:  15.1372\n",
      "Epoch 272, Reconstruct Loss: -29.4332,KLD Loss:  17.3914\n",
      "Epoch 273, Reconstruct Loss: -31.7743,KLD Loss:  16.8267\n",
      "Epoch 274, Reconstruct Loss: -29.9765,KLD Loss:  16.9012\n",
      "Epoch 275, Reconstruct Loss: -29.8015,KLD Loss:  16.8283\n",
      "Epoch 276, Reconstruct Loss: -29.9128,KLD Loss:  17.0955\n",
      "Epoch 277, Reconstruct Loss: -27.7593,KLD Loss:  16.8444\n",
      "Epoch 278, Reconstruct Loss: -29.6589,KLD Loss:  16.4780\n",
      "Epoch 279, Reconstruct Loss: -28.1191,KLD Loss:  15.4867\n",
      "Epoch 280, Reconstruct Loss: -31.3204,KLD Loss:  16.3821\n",
      "Epoch 281, Reconstruct Loss: -27.8078,KLD Loss:  18.0098\n",
      "Epoch 282, Reconstruct Loss: -31.0525,KLD Loss:  18.8337\n",
      "Epoch 283, Reconstruct Loss: -29.3224,KLD Loss:  15.4127\n",
      "Epoch 284, Reconstruct Loss: -27.5206,KLD Loss:  18.3898\n",
      "Epoch 285, Reconstruct Loss: -30.8420,KLD Loss:  17.7001\n",
      "Epoch 286, Reconstruct Loss: -30.3457,KLD Loss:  17.1215\n",
      "Epoch 287, Reconstruct Loss: -29.7842,KLD Loss:  16.6720\n",
      "Epoch 288, Reconstruct Loss: -31.6628,KLD Loss:  18.2549\n",
      "Epoch 289, Reconstruct Loss: -31.0827,KLD Loss:  17.8364\n",
      "Epoch 290, Reconstruct Loss: -29.5438,KLD Loss:  16.9167\n",
      "Epoch 291, Reconstruct Loss: -29.5241,KLD Loss:  16.3255\n",
      "Epoch 292, Reconstruct Loss: -30.4309,KLD Loss:  16.6183\n",
      "Epoch 293, Reconstruct Loss: -31.3897,KLD Loss:  16.9009\n",
      "Epoch 294, Reconstruct Loss: -30.2760,KLD Loss:  19.0899\n",
      "Epoch 295, Reconstruct Loss: -29.2229,KLD Loss:  17.6386\n",
      "Epoch 296, Reconstruct Loss: -32.8174,KLD Loss:  17.3384\n",
      "Epoch 297, Reconstruct Loss: -30.3812,KLD Loss:  17.9125\n",
      "Epoch 298, Reconstruct Loss: -31.9901,KLD Loss:  17.2308\n",
      "Epoch 299, Reconstruct Loss: -30.2892,KLD Loss:  16.7414\n",
      "Epoch 300, Reconstruct Loss: -31.5039,KLD Loss:  17.2946\n",
      "Fine Tuning Generation Task\n",
      "mode collapse correction\n",
      "[' Amer-Indian-Eskimo']\n",
      "[' Canada', ' Columbia', ' England', ' France', ' Germany', ' Greece', ' Haiti', ' Holand-Netherlands', ' Honduras', ' Hong', ' Hungary', ' Iran', ' Ireland', ' Nicaragua', ' Outlying-US(Guam-USVI-etc)', ' Peru', ' Poland', ' Portugal', ' Scotland', ' Thailand', ' Trinadad&Tobago', ' Yugoslavia']\n",
      "rare from train :  1172\n",
      "Epoch 1, Reconstruct Loss: -8.5458,KLD Loss:  18.1157\n",
      "Epoch 2, Reconstruct Loss:  19.2208,KLD Loss:  18.4289\n",
      "Epoch 3, Reconstruct Loss: -12.8905,KLD Loss:  18.6012\n",
      "Epoch 4, Reconstruct Loss: -3.9842,KLD Loss:  18.1933\n",
      "Epoch 5, Reconstruct Loss: -15.7912,KLD Loss:  17.6483\n",
      "Epoch 6, Reconstruct Loss: -17.0054,KLD Loss:  17.2836\n",
      "Epoch 7, Reconstruct Loss: -14.0909,KLD Loss:  17.3646\n",
      "Epoch 8, Reconstruct Loss: -17.8028,KLD Loss:  17.1924\n",
      "Epoch 9, Reconstruct Loss: -19.1283,KLD Loss:  16.3580\n",
      "Epoch 10, Reconstruct Loss: -18.6177,KLD Loss:  16.4590\n",
      "Epoch 11, Reconstruct Loss: -18.5165,KLD Loss:  16.4000\n",
      "Epoch 12, Reconstruct Loss: -21.1921,KLD Loss:  16.4675\n",
      "Epoch 13, Reconstruct Loss: -20.2443,KLD Loss:  16.5902\n",
      "Epoch 14, Reconstruct Loss: -21.0000,KLD Loss:  16.5288\n",
      "Epoch 15, Reconstruct Loss: -21.4585,KLD Loss:  16.8499\n",
      "Epoch 16, Reconstruct Loss: -21.7284,KLD Loss:  16.8338\n",
      "Epoch 17, Reconstruct Loss: -23.0491,KLD Loss:  16.7601\n",
      "Epoch 18, Reconstruct Loss: -23.7765,KLD Loss:  17.2598\n",
      "Epoch 19, Reconstruct Loss: -24.3272,KLD Loss:  16.7156\n",
      "Epoch 20, Reconstruct Loss: -23.8480,KLD Loss:  17.2474\n",
      "Epoch 21, Reconstruct Loss: -23.7094,KLD Loss:  16.8033\n",
      "Epoch 22, Reconstruct Loss: -24.5095,KLD Loss:  17.1872\n",
      "Epoch 23, Reconstruct Loss: -25.0082,KLD Loss:  17.4359\n",
      "Epoch 24, Reconstruct Loss: -24.5726,KLD Loss:  16.9537\n",
      "Epoch 25, Reconstruct Loss: -25.7599,KLD Loss:  16.9551\n",
      "Epoch 26, Reconstruct Loss: -26.3185,KLD Loss:  17.2903\n",
      "Epoch 27, Reconstruct Loss: -25.9179,KLD Loss:  17.5714\n",
      "Epoch 28, Reconstruct Loss: -25.9238,KLD Loss:  17.5135\n",
      "Epoch 29, Reconstruct Loss: -27.0783,KLD Loss:  17.4658\n",
      "Epoch 30, Reconstruct Loss: -26.8295,KLD Loss:  17.9775\n",
      "Epoch 31, Reconstruct Loss: -26.9048,KLD Loss:  17.7890\n",
      "Epoch 32, Reconstruct Loss: -26.8620,KLD Loss:  18.1077\n",
      "Epoch 33, Reconstruct Loss: -26.8910,KLD Loss:  18.3006\n",
      "Epoch 34, Reconstruct Loss: -25.8460,KLD Loss:  18.0989\n",
      "Epoch 35, Reconstruct Loss: -25.8848,KLD Loss:  18.0962\n",
      "Epoch 36, Reconstruct Loss: -27.2123,KLD Loss:  18.0286\n",
      "Epoch 37, Reconstruct Loss: -25.6995,KLD Loss:  17.9210\n",
      "Epoch 38, Reconstruct Loss: -27.9066,KLD Loss:  18.2497\n",
      "Epoch 39, Reconstruct Loss: -27.6468,KLD Loss:  18.1536\n",
      "Epoch 40, Reconstruct Loss: -27.6866,KLD Loss:  17.7134\n",
      "Epoch 41, Reconstruct Loss: -27.3856,KLD Loss:  18.1829\n",
      "Epoch 42, Reconstruct Loss: -27.6135,KLD Loss:  18.3011\n",
      "Epoch 43, Reconstruct Loss: -27.6388,KLD Loss:  18.0437\n",
      "Epoch 44, Reconstruct Loss: -27.3602,KLD Loss:  17.9074\n",
      "Epoch 45, Reconstruct Loss: -27.7765,KLD Loss:  17.7705\n",
      "Epoch 46, Reconstruct Loss: -26.1888,KLD Loss:  18.2531\n",
      "Epoch 47, Reconstruct Loss: -26.9109,KLD Loss:  18.4251\n",
      "Epoch 48, Reconstruct Loss: -27.2363,KLD Loss:  17.8434\n",
      "Epoch 49, Reconstruct Loss: -27.5039,KLD Loss:  18.0991\n",
      "Epoch 50, Reconstruct Loss: -28.2083,KLD Loss:  18.1042\n",
      "Epoch 51, Reconstruct Loss: -26.9354,KLD Loss:  18.7288\n",
      "Epoch 52, Reconstruct Loss: -27.7372,KLD Loss:  18.2333\n",
      "Epoch 53, Reconstruct Loss: -27.8132,KLD Loss:  18.0132\n",
      "Epoch 54, Reconstruct Loss: -27.5503,KLD Loss:  18.0855\n",
      "Epoch 55, Reconstruct Loss: -27.4616,KLD Loss:  18.3689\n",
      "Epoch 56, Reconstruct Loss: -27.2447,KLD Loss:  18.4474\n",
      "Epoch 57, Reconstruct Loss: -27.2993,KLD Loss:  18.5110\n",
      "Epoch 58, Reconstruct Loss: -27.1906,KLD Loss:  18.1111\n",
      "Epoch 59, Reconstruct Loss: -27.1964,KLD Loss:  18.1754\n",
      "Epoch 60, Reconstruct Loss: -28.5583,KLD Loss:  18.3502\n",
      "Epoch 61, Reconstruct Loss: -27.5079,KLD Loss:  17.9135\n",
      "Epoch 62, Reconstruct Loss: -28.1003,KLD Loss:  18.6674\n",
      "Epoch 63, Reconstruct Loss: -29.3610,KLD Loss:  18.2617\n",
      "Epoch 64, Reconstruct Loss: -28.3447,KLD Loss:  18.2548\n",
      "Epoch 65, Reconstruct Loss: -27.6681,KLD Loss:  18.5392\n",
      "Epoch 66, Reconstruct Loss: -28.9587,KLD Loss:  18.1472\n",
      "Epoch 67, Reconstruct Loss: -27.7908,KLD Loss:  18.0133\n",
      "Epoch 68, Reconstruct Loss: -28.0684,KLD Loss:  18.4050\n",
      "Epoch 69, Reconstruct Loss: -27.9194,KLD Loss:  18.2680\n",
      "Epoch 70, Reconstruct Loss: -27.3611,KLD Loss:  17.9425\n",
      "Epoch 71, Reconstruct Loss: -27.3389,KLD Loss:  18.8045\n",
      "Epoch 72, Reconstruct Loss: -29.0166,KLD Loss:  18.3425\n",
      "Epoch 73, Reconstruct Loss: -28.0600,KLD Loss:  18.6132\n",
      "Epoch 74, Reconstruct Loss: -28.3107,KLD Loss:  18.3773\n",
      "Epoch 75, Reconstruct Loss: -28.2489,KLD Loss:  18.0760\n",
      "Epoch 76, Reconstruct Loss: -28.3634,KLD Loss:  18.4547\n",
      "Epoch 77, Reconstruct Loss: -28.9513,KLD Loss:  18.5426\n",
      "Epoch 78, Reconstruct Loss: -28.1952,KLD Loss:  18.2703\n",
      "Epoch 79, Reconstruct Loss: -27.6818,KLD Loss:  18.5692\n",
      "Epoch 80, Reconstruct Loss: -29.1874,KLD Loss:  18.4026\n",
      "Epoch 81, Reconstruct Loss: -29.3663,KLD Loss:  18.4593\n",
      "Epoch 82, Reconstruct Loss: -28.5968,KLD Loss:  18.4627\n",
      "Epoch 83, Reconstruct Loss: -29.0632,KLD Loss:  17.8383\n",
      "Epoch 84, Reconstruct Loss: -28.3868,KLD Loss:  18.2477\n",
      "Epoch 85, Reconstruct Loss: -29.0551,KLD Loss:  18.3543\n",
      "Epoch 86, Reconstruct Loss: -29.4326,KLD Loss:  18.7979\n",
      "Epoch 87, Reconstruct Loss: -28.9389,KLD Loss:  17.9226\n",
      "Epoch 88, Reconstruct Loss: -28.4251,KLD Loss:  18.4689\n",
      "Epoch 89, Reconstruct Loss: -29.1873,KLD Loss:  18.4040\n",
      "Epoch 90, Reconstruct Loss: -29.4009,KLD Loss:  18.8046\n",
      "Epoch 91, Reconstruct Loss: -27.5471,KLD Loss:  18.9038\n",
      "Epoch 92, Reconstruct Loss: -28.2041,KLD Loss:  18.6451\n",
      "Epoch 93, Reconstruct Loss: -28.6540,KLD Loss:  18.8041\n",
      "Epoch 94, Reconstruct Loss: -28.2820,KLD Loss:  18.6635\n",
      "Epoch 95, Reconstruct Loss: -29.3636,KLD Loss:  18.4964\n",
      "Epoch 96, Reconstruct Loss: -29.2235,KLD Loss:  18.3130\n",
      "Epoch 97, Reconstruct Loss: -29.0918,KLD Loss:  18.0954\n",
      "Epoch 98, Reconstruct Loss: -28.0684,KLD Loss:  18.6713\n",
      "Epoch 99, Reconstruct Loss: -29.1828,KLD Loss:  19.0068\n",
      "Epoch 100, Reconstruct Loss: -28.0726,KLD Loss:  18.2744\n",
      "Epoch 101, Reconstruct Loss: -29.8689,KLD Loss:  18.3084\n",
      "Epoch 102, Reconstruct Loss: -29.3218,KLD Loss:  19.0090\n",
      "Epoch 103, Reconstruct Loss: -28.7921,KLD Loss:  18.8064\n",
      "Epoch 104, Reconstruct Loss: -28.7091,KLD Loss:  18.5995\n",
      "Epoch 105, Reconstruct Loss: -29.3453,KLD Loss:  18.2123\n",
      "Epoch 106, Reconstruct Loss: -28.6847,KLD Loss:  18.3206\n",
      "Epoch 107, Reconstruct Loss: -28.0407,KLD Loss:  18.7177\n",
      "Epoch 108, Reconstruct Loss: -29.1791,KLD Loss:  18.6249\n",
      "Epoch 109, Reconstruct Loss: -29.4889,KLD Loss:  18.6398\n",
      "Epoch 110, Reconstruct Loss: -30.5199,KLD Loss:  18.6403\n",
      "Epoch 111, Reconstruct Loss: -29.8788,KLD Loss:  18.8038\n",
      "Epoch 112, Reconstruct Loss: -29.2254,KLD Loss:  18.2602\n",
      "Epoch 113, Reconstruct Loss: -29.7199,KLD Loss:  18.1601\n",
      "Epoch 114, Reconstruct Loss: -29.0703,KLD Loss:  18.6743\n",
      "Epoch 115, Reconstruct Loss: -29.1666,KLD Loss:  18.1729\n",
      "Epoch 116, Reconstruct Loss: -29.3381,KLD Loss:  18.7791\n",
      "Epoch 117, Reconstruct Loss: -29.2744,KLD Loss:  18.6452\n",
      "Epoch 118, Reconstruct Loss: -29.6368,KLD Loss:  19.0486\n",
      "Epoch 119, Reconstruct Loss: -29.1762,KLD Loss:  19.2305\n",
      "Epoch 120, Reconstruct Loss: -29.6579,KLD Loss:  18.6412\n",
      "Epoch 121, Reconstruct Loss: -29.6882,KLD Loss:  18.7128\n",
      "Epoch 122, Reconstruct Loss: -30.0697,KLD Loss:  18.5823\n",
      "Epoch 123, Reconstruct Loss: -29.4897,KLD Loss:  18.8066\n",
      "Epoch 124, Reconstruct Loss: -29.8502,KLD Loss:  19.0835\n",
      "Epoch 125, Reconstruct Loss: -30.0267,KLD Loss:  19.1250\n",
      "Epoch 126, Reconstruct Loss: -30.2377,KLD Loss:  18.7123\n",
      "Epoch 127, Reconstruct Loss: -30.2124,KLD Loss:  18.5679\n",
      "Epoch 128, Reconstruct Loss: -30.0151,KLD Loss:  18.5355\n",
      "Epoch 129, Reconstruct Loss: -29.2301,KLD Loss:  18.9210\n",
      "Epoch 130, Reconstruct Loss: -27.6776,KLD Loss:  18.1981\n",
      "Epoch 131, Reconstruct Loss: -30.6626,KLD Loss:  18.7173\n",
      "Epoch 132, Reconstruct Loss: -30.1008,KLD Loss:  18.4440\n",
      "Epoch 133, Reconstruct Loss: -29.2744,KLD Loss:  19.1997\n",
      "Epoch 134, Reconstruct Loss: -29.4072,KLD Loss:  19.5448\n",
      "Epoch 135, Reconstruct Loss: -29.3164,KLD Loss:  19.3449\n",
      "Epoch 136, Reconstruct Loss: -30.1112,KLD Loss:  19.6084\n",
      "Epoch 137, Reconstruct Loss: -30.3373,KLD Loss:  19.2633\n",
      "Epoch 138, Reconstruct Loss: -29.4567,KLD Loss:  18.9769\n",
      "Epoch 139, Reconstruct Loss: -30.1383,KLD Loss:  19.6222\n",
      "Epoch 140, Reconstruct Loss: -29.7517,KLD Loss:  18.8813\n",
      "Epoch 141, Reconstruct Loss: -29.9034,KLD Loss:  18.6712\n",
      "Epoch 142, Reconstruct Loss: -29.8922,KLD Loss:  18.9020\n",
      "Epoch 143, Reconstruct Loss: -29.5214,KLD Loss:  19.1100\n",
      "Epoch 144, Reconstruct Loss: -29.4635,KLD Loss:  19.1353\n",
      "Epoch 145, Reconstruct Loss: -30.4792,KLD Loss:  18.7554\n",
      "Epoch 146, Reconstruct Loss: -30.7286,KLD Loss:  19.4714\n",
      "Epoch 147, Reconstruct Loss: -31.2256,KLD Loss:  19.2950\n",
      "Epoch 148, Reconstruct Loss: -29.8296,KLD Loss:  19.0699\n",
      "Epoch 149, Reconstruct Loss: -30.1804,KLD Loss:  19.4875\n",
      "Epoch 150, Reconstruct Loss: -29.9820,KLD Loss:  18.7705\n",
      "Epoch 151, Reconstruct Loss: -31.1524,KLD Loss:  18.8542\n",
      "Epoch 152, Reconstruct Loss: -28.7079,KLD Loss:  19.2138\n",
      "Epoch 153, Reconstruct Loss: -28.7875,KLD Loss:  19.5203\n",
      "Epoch 154, Reconstruct Loss: -30.5222,KLD Loss:  18.7722\n",
      "Epoch 155, Reconstruct Loss: -31.0398,KLD Loss:  19.0822\n",
      "Epoch 156, Reconstruct Loss: -30.4609,KLD Loss:  18.7850\n",
      "Epoch 157, Reconstruct Loss: -29.0998,KLD Loss:  19.0311\n",
      "Epoch 158, Reconstruct Loss: -29.9841,KLD Loss:  18.9841\n",
      "Epoch 159, Reconstruct Loss: -29.2413,KLD Loss:  19.0441\n",
      "Epoch 160, Reconstruct Loss: -30.2367,KLD Loss:  18.8651\n",
      "Epoch 161, Reconstruct Loss: -30.2640,KLD Loss:  18.9250\n",
      "Epoch 162, Reconstruct Loss: -30.0574,KLD Loss:  19.0185\n",
      "Epoch 163, Reconstruct Loss: -29.2457,KLD Loss:  19.2717\n",
      "Epoch 164, Reconstruct Loss: -29.7981,KLD Loss:  18.9169\n",
      "Epoch 165, Reconstruct Loss: -28.0004,KLD Loss:  18.9283\n",
      "Epoch 166, Reconstruct Loss: -30.3229,KLD Loss:  19.5990\n",
      "Epoch 167, Reconstruct Loss: -30.3921,KLD Loss:  19.2892\n",
      "Epoch 168, Reconstruct Loss: -30.4097,KLD Loss:  19.4849\n",
      "Epoch 169, Reconstruct Loss: -29.3291,KLD Loss:  19.4121\n",
      "Epoch 170, Reconstruct Loss: -29.6218,KLD Loss:  19.4634\n",
      "Epoch 171, Reconstruct Loss: -30.6109,KLD Loss:  19.1948\n",
      "Epoch 172, Reconstruct Loss: -28.6184,KLD Loss:  19.0967\n",
      "Epoch 173, Reconstruct Loss: -30.5865,KLD Loss:  19.0202\n",
      "Epoch 174, Reconstruct Loss: -29.2085,KLD Loss:  18.9343\n",
      "Epoch 175, Reconstruct Loss: -30.6263,KLD Loss:  19.0077\n",
      "Epoch 176, Reconstruct Loss: -30.2488,KLD Loss:  18.7874\n",
      "Epoch 177, Reconstruct Loss: -30.0516,KLD Loss:  19.1990\n",
      "Epoch 178, Reconstruct Loss: -28.9320,KLD Loss:  19.0816\n",
      "Epoch 179, Reconstruct Loss: -30.2054,KLD Loss:  19.0180\n",
      "Epoch 180, Reconstruct Loss: -30.1080,KLD Loss:  19.0283\n",
      "Epoch 181, Reconstruct Loss: -29.3396,KLD Loss:  18.9086\n",
      "Epoch 182, Reconstruct Loss: -29.9715,KLD Loss:  18.9890\n",
      "Epoch 183, Reconstruct Loss: -31.4860,KLD Loss:  19.1338\n",
      "Epoch 184, Reconstruct Loss: -29.7779,KLD Loss:  19.1923\n",
      "Epoch 185, Reconstruct Loss: -28.9742,KLD Loss:  19.5415\n",
      "Epoch 186, Reconstruct Loss: -31.3091,KLD Loss:  19.0624\n",
      "Epoch 187, Reconstruct Loss: -29.7416,KLD Loss:  19.4262\n",
      "Epoch 188, Reconstruct Loss: -30.4001,KLD Loss:  19.0111\n",
      "Epoch 189, Reconstruct Loss: -30.8008,KLD Loss:  19.4627\n",
      "Epoch 190, Reconstruct Loss: -30.1313,KLD Loss:  19.2074\n",
      "Epoch 191, Reconstruct Loss: -30.5960,KLD Loss:  18.9558\n",
      "Epoch 192, Reconstruct Loss: -29.7615,KLD Loss:  19.2933\n",
      "Epoch 193, Reconstruct Loss: -31.0545,KLD Loss:  18.5976\n",
      "Epoch 194, Reconstruct Loss: -30.3181,KLD Loss:  19.2575\n",
      "Epoch 195, Reconstruct Loss: -30.7795,KLD Loss:  18.6684\n",
      "Epoch 196, Reconstruct Loss: -30.8977,KLD Loss:  19.1138\n",
      "Epoch 197, Reconstruct Loss: -31.2224,KLD Loss:  18.7766\n",
      "Epoch 198, Reconstruct Loss: -28.7601,KLD Loss:  18.8272\n",
      "Epoch 199, Reconstruct Loss: -30.3327,KLD Loss:  18.7961\n",
      "Epoch 200, Reconstruct Loss: -29.8416,KLD Loss:  18.9375\n",
      "Epoch 201, Reconstruct Loss: -30.8093,KLD Loss:  19.8398\n",
      "Epoch 202, Reconstruct Loss: -31.1993,KLD Loss:  19.2803\n",
      "Epoch 203, Reconstruct Loss: -30.6007,KLD Loss:  19.6766\n",
      "Epoch 204, Reconstruct Loss: -29.7236,KLD Loss:  19.3945\n",
      "Epoch 205, Reconstruct Loss: -29.3992,KLD Loss:  19.2948\n",
      "Epoch 206, Reconstruct Loss: -29.8026,KLD Loss:  19.1030\n",
      "Epoch 207, Reconstruct Loss: -29.5269,KLD Loss:  19.2336\n",
      "Epoch 208, Reconstruct Loss: -29.6597,KLD Loss:  19.0193\n",
      "Epoch 209, Reconstruct Loss: -29.6847,KLD Loss:  19.2677\n",
      "Epoch 210, Reconstruct Loss: -30.1324,KLD Loss:  19.1624\n",
      "Epoch 211, Reconstruct Loss: -30.0381,KLD Loss:  19.5239\n",
      "Epoch 212, Reconstruct Loss: -30.5717,KLD Loss:  19.2818\n",
      "Epoch 213, Reconstruct Loss: -30.3910,KLD Loss:  18.9677\n",
      "Epoch 214, Reconstruct Loss: -30.1871,KLD Loss:  19.3875\n",
      "Epoch 215, Reconstruct Loss: -30.4539,KLD Loss:  19.1081\n",
      "Epoch 216, Reconstruct Loss: -29.8337,KLD Loss:  19.4032\n",
      "Epoch 217, Reconstruct Loss: -30.4770,KLD Loss:  18.7456\n",
      "Epoch 218, Reconstruct Loss: -30.5649,KLD Loss:  20.2092\n",
      "Epoch 219, Reconstruct Loss: -30.5634,KLD Loss:  19.1971\n",
      "Epoch 220, Reconstruct Loss: -30.8151,KLD Loss:  19.0512\n",
      "Epoch 221, Reconstruct Loss: -30.6806,KLD Loss:  19.0754\n",
      "Epoch 222, Reconstruct Loss: -29.6926,KLD Loss:  18.7939\n",
      "Epoch 223, Reconstruct Loss: -30.2674,KLD Loss:  19.0596\n",
      "Epoch 224, Reconstruct Loss: -30.6454,KLD Loss:  19.6184\n",
      "Epoch 225, Reconstruct Loss: -29.9858,KLD Loss:  19.1742\n",
      "Epoch 226, Reconstruct Loss: -31.6756,KLD Loss:  18.9246\n",
      "Epoch 227, Reconstruct Loss: -29.2656,KLD Loss:  18.5452\n",
      "Epoch 228, Reconstruct Loss: -30.6420,KLD Loss:  18.6531\n",
      "Epoch 229, Reconstruct Loss: -30.2899,KLD Loss:  18.5803\n",
      "Epoch 230, Reconstruct Loss: -30.4176,KLD Loss:  18.6435\n",
      "Epoch 231, Reconstruct Loss: -29.1011,KLD Loss:  18.6057\n",
      "Epoch 232, Reconstruct Loss: -30.7060,KLD Loss:  19.0370\n",
      "Epoch 233, Reconstruct Loss: -30.3544,KLD Loss:  18.3255\n",
      "Epoch 234, Reconstruct Loss: -30.0998,KLD Loss:  19.1233\n",
      "Epoch 235, Reconstruct Loss: -30.7371,KLD Loss:  18.9780\n",
      "Epoch 236, Reconstruct Loss: -30.8118,KLD Loss:  18.8578\n",
      "Epoch 237, Reconstruct Loss: -30.1241,KLD Loss:  18.9305\n",
      "Epoch 238, Reconstruct Loss: -31.4025,KLD Loss:  19.1884\n",
      "Epoch 239, Reconstruct Loss: -31.3141,KLD Loss:  19.1122\n",
      "Epoch 240, Reconstruct Loss: -30.3404,KLD Loss:  18.8849\n",
      "Epoch 241, Reconstruct Loss: -30.0172,KLD Loss:  18.4782\n",
      "Epoch 242, Reconstruct Loss: -30.2110,KLD Loss:  19.0142\n",
      "Epoch 243, Reconstruct Loss: -30.1105,KLD Loss:  19.5467\n",
      "Epoch 244, Reconstruct Loss: -30.9774,KLD Loss:  19.4428\n",
      "Epoch 245, Reconstruct Loss: -30.4544,KLD Loss:  19.1730\n",
      "Epoch 246, Reconstruct Loss: -31.3303,KLD Loss:  18.5514\n",
      "Epoch 247, Reconstruct Loss: -31.5659,KLD Loss:  18.9812\n",
      "Epoch 248, Reconstruct Loss: -30.4846,KLD Loss:  18.6374\n",
      "Epoch 249, Reconstruct Loss: -30.7159,KLD Loss:  18.8116\n",
      "Epoch 250, Reconstruct Loss: -30.4108,KLD Loss:  19.1054\n",
      "Epoch 251, Reconstruct Loss: -31.0183,KLD Loss:  18.9183\n",
      "Epoch 252, Reconstruct Loss: -30.1644,KLD Loss:  19.0193\n",
      "Epoch 253, Reconstruct Loss: -31.0442,KLD Loss:  18.9662\n",
      "Epoch 254, Reconstruct Loss: -31.3520,KLD Loss:  18.9619\n",
      "Epoch 255, Reconstruct Loss: -30.5314,KLD Loss:  19.1531\n",
      "Epoch 256, Reconstruct Loss: -30.9418,KLD Loss:  19.1395\n",
      "Epoch 257, Reconstruct Loss: -31.5268,KLD Loss:  19.0405\n",
      "Epoch 258, Reconstruct Loss: -29.1404,KLD Loss:  19.3232\n",
      "Epoch 259, Reconstruct Loss: -30.8555,KLD Loss:  18.9304\n",
      "Epoch 260, Reconstruct Loss: -31.2208,KLD Loss:  19.4516\n",
      "Epoch 261, Reconstruct Loss: -31.2540,KLD Loss:  19.1344\n",
      "Epoch 262, Reconstruct Loss: -31.1799,KLD Loss:  19.6590\n",
      "Epoch 263, Reconstruct Loss: -32.2361,KLD Loss:  18.7648\n",
      "Epoch 264, Reconstruct Loss: -29.9903,KLD Loss:  19.1946\n",
      "Epoch 265, Reconstruct Loss: -31.7073,KLD Loss:  18.9416\n",
      "Epoch 266, Reconstruct Loss: -32.0472,KLD Loss:  19.0166\n",
      "Epoch 267, Reconstruct Loss: -30.7031,KLD Loss:  19.0182\n",
      "Epoch 268, Reconstruct Loss: -30.9548,KLD Loss:  18.9926\n",
      "Epoch 269, Reconstruct Loss: -31.2888,KLD Loss:  19.0089\n",
      "Epoch 270, Reconstruct Loss: -30.5426,KLD Loss:  19.3180\n",
      "Epoch 271, Reconstruct Loss: -30.5071,KLD Loss:  19.4591\n",
      "Epoch 272, Reconstruct Loss: -29.8168,KLD Loss:  19.1418\n",
      "Epoch 273, Reconstruct Loss: -31.3991,KLD Loss:  19.3300\n",
      "Epoch 274, Reconstruct Loss: -31.5191,KLD Loss:  19.2460\n",
      "Epoch 275, Reconstruct Loss: -31.8659,KLD Loss:  18.8265\n",
      "Epoch 276, Reconstruct Loss: -30.7119,KLD Loss:  19.5677\n",
      "Epoch 277, Reconstruct Loss: -31.1961,KLD Loss:  18.9662\n",
      "Epoch 278, Reconstruct Loss: -30.3615,KLD Loss:  19.5959\n",
      "Epoch 279, Reconstruct Loss: -31.0023,KLD Loss:  19.0811\n",
      "Epoch 280, Reconstruct Loss: -30.6482,KLD Loss:  19.3438\n",
      "Epoch 281, Reconstruct Loss: -31.3777,KLD Loss:  19.2982\n",
      "Epoch 282, Reconstruct Loss: -30.6130,KLD Loss:  19.4292\n",
      "Epoch 283, Reconstruct Loss: -32.0580,KLD Loss:  18.9865\n",
      "Epoch 284, Reconstruct Loss: -30.9477,KLD Loss:  19.5709\n",
      "Epoch 285, Reconstruct Loss: -30.4281,KLD Loss:  19.1685\n",
      "Epoch 286, Reconstruct Loss: -31.0696,KLD Loss:  18.6832\n",
      "Epoch 287, Reconstruct Loss: -29.8651,KLD Loss:  19.9592\n",
      "Epoch 288, Reconstruct Loss: -31.2582,KLD Loss:  19.4665\n",
      "Epoch 289, Reconstruct Loss: -31.1213,KLD Loss:  19.2330\n",
      "Epoch 290, Reconstruct Loss: -29.6224,KLD Loss:  19.2125\n",
      "Epoch 291, Reconstruct Loss: -30.8125,KLD Loss:  19.2792\n",
      "Epoch 292, Reconstruct Loss: -30.5420,KLD Loss:  19.2109\n",
      "Epoch 293, Reconstruct Loss: -30.6349,KLD Loss:  19.0428\n",
      "Epoch 294, Reconstruct Loss: -31.6397,KLD Loss:  18.6852\n",
      "Epoch 295, Reconstruct Loss: -30.5836,KLD Loss:  19.3266\n",
      "Epoch 296, Reconstruct Loss: -31.1576,KLD Loss:  18.9555\n",
      "Epoch 297, Reconstruct Loss: -29.9509,KLD Loss:  19.0164\n",
      "Epoch 298, Reconstruct Loss: -29.9726,KLD Loss:  18.7990\n",
      "Epoch 299, Reconstruct Loss: -30.5642,KLD Loss:  19.2460\n",
      "Epoch 300, Reconstruct Loss: -30.4666,KLD Loss:  18.6741\n",
      "filter_mask :  True\n",
      "len filtered_df : 7118\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 2637\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 880\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 1841\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 435\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 5030\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 195\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 1711\n",
      "df_combined : 10\n",
      "filter_mask :  False\n",
      "len filtered_df : 0\n",
      "df_combined : 0\n",
      "filter_mask :  True\n",
      "len filtered_df : 43\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 632\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 133\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 522\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 93\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 266\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 116\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 449\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 968\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 733\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 10\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 582\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 399\n",
      "df_combined : 10\n",
      "filter_mask :  True\n",
      "len filtered_df : 46\n",
      "df_combined : 10\n",
      "mode collapse correction\n",
      "[' Holand-Netherlands']\n",
      "rare from train :  1\n",
      "Epoch 1, Reconstruct Loss:  45.8888,KLD Loss:  20.9631\n",
      "Epoch 2, Reconstruct Loss:  183.4266,KLD Loss:  21.6515\n",
      "Epoch 3, Reconstruct Loss:  11.1545,KLD Loss:  21.3326\n",
      "Epoch 4, Reconstruct Loss: -1.5134,KLD Loss:  21.0433\n",
      "Epoch 5, Reconstruct Loss:  46.8329,KLD Loss:  20.7940\n",
      "Epoch 6, Reconstruct Loss:  53.2135,KLD Loss:  20.5982\n",
      "Epoch 7, Reconstruct Loss:  21.9462,KLD Loss:  20.4727\n",
      "Epoch 8, Reconstruct Loss:  1.3253,KLD Loss:  20.3221\n",
      "Epoch 9, Reconstruct Loss: -5.7736,KLD Loss:  20.2224\n",
      "Epoch 10, Reconstruct Loss:  4.4692,KLD Loss:  20.1349\n",
      "Epoch 11, Reconstruct Loss:  11.7626,KLD Loss:  20.0576\n",
      "Epoch 12, Reconstruct Loss:  12.1917,KLD Loss:  20.0312\n",
      "Epoch 13, Reconstruct Loss:  9.2988,KLD Loss:  20.0028\n",
      "Epoch 14, Reconstruct Loss: -5.1749,KLD Loss:  19.9777\n",
      "Epoch 15, Reconstruct Loss: -2.1855,KLD Loss:  19.9481\n",
      "Epoch 16, Reconstruct Loss: -9.5494,KLD Loss:  19.9286\n",
      "Epoch 17, Reconstruct Loss: -9.9439,KLD Loss:  19.9333\n",
      "Epoch 18, Reconstruct Loss: -8.0970,KLD Loss:  19.9819\n",
      "Epoch 19, Reconstruct Loss: -12.4582,KLD Loss:  20.0729\n",
      "Epoch 20, Reconstruct Loss: -14.2709,KLD Loss:  20.1703\n",
      "Epoch 21, Reconstruct Loss: -14.8243,KLD Loss:  20.2573\n",
      "Epoch 22, Reconstruct Loss: -20.1511,KLD Loss:  20.3521\n",
      "Epoch 23, Reconstruct Loss: -23.7964,KLD Loss:  20.4113\n",
      "Epoch 24, Reconstruct Loss: -22.3331,KLD Loss:  20.4632\n",
      "Epoch 25, Reconstruct Loss: -24.7808,KLD Loss:  20.5168\n",
      "Epoch 26, Reconstruct Loss: -26.6752,KLD Loss:  20.5772\n",
      "Epoch 27, Reconstruct Loss: -7.4237,KLD Loss:  20.5878\n",
      "Epoch 28, Reconstruct Loss: -14.3865,KLD Loss:  20.5788\n",
      "Epoch 29, Reconstruct Loss: -33.3295,KLD Loss:  20.6293\n",
      "Epoch 30, Reconstruct Loss: -19.1802,KLD Loss:  20.6554\n",
      "Epoch 31, Reconstruct Loss: -33.1443,KLD Loss:  20.7215\n",
      "Epoch 32, Reconstruct Loss: -23.1800,KLD Loss:  20.7538\n",
      "Epoch 33, Reconstruct Loss: -33.0530,KLD Loss:  20.7817\n",
      "Epoch 34, Reconstruct Loss: -22.9051,KLD Loss:  20.8000\n",
      "Epoch 35, Reconstruct Loss: -30.8919,KLD Loss:  20.8065\n",
      "Epoch 36, Reconstruct Loss: -32.5515,KLD Loss:  20.8604\n",
      "Epoch 37, Reconstruct Loss: -22.7495,KLD Loss:  20.9145\n",
      "Epoch 38, Reconstruct Loss: -32.6207,KLD Loss:  20.9971\n",
      "Epoch 39, Reconstruct Loss: -40.1754,KLD Loss:  21.0417\n",
      "Epoch 40, Reconstruct Loss: -40.1966,KLD Loss:  21.0745\n",
      "Epoch 41, Reconstruct Loss: -30.4168,KLD Loss:  21.0702\n",
      "Epoch 42, Reconstruct Loss: -39.1194,KLD Loss:  21.0843\n",
      "Epoch 43, Reconstruct Loss: -28.8326,KLD Loss:  21.0879\n",
      "Epoch 44, Reconstruct Loss: -33.1954,KLD Loss:  21.1780\n",
      "Epoch 45, Reconstruct Loss: -39.0013,KLD Loss:  21.2873\n",
      "Epoch 46, Reconstruct Loss: -34.1925,KLD Loss:  21.3213\n",
      "Epoch 47, Reconstruct Loss: -40.8597,KLD Loss:  21.3856\n",
      "Epoch 48, Reconstruct Loss: -41.5325,KLD Loss:  21.3980\n",
      "Epoch 49, Reconstruct Loss: -37.6974,KLD Loss:  21.3659\n",
      "Epoch 50, Reconstruct Loss: -41.6187,KLD Loss:  21.3742\n",
      "Epoch 51, Reconstruct Loss: -42.4016,KLD Loss:  21.3497\n",
      "Epoch 52, Reconstruct Loss: -36.8449,KLD Loss:  21.2847\n",
      "Epoch 53, Reconstruct Loss: -41.6019,KLD Loss:  21.2416\n",
      "Epoch 54, Reconstruct Loss: -42.4532,KLD Loss:  21.1919\n",
      "Epoch 55, Reconstruct Loss: -38.2827,KLD Loss:  21.1130\n",
      "Epoch 56, Reconstruct Loss: -41.1211,KLD Loss:  21.0313\n",
      "Epoch 57, Reconstruct Loss: -35.1715,KLD Loss:  20.9449\n",
      "Epoch 58, Reconstruct Loss: -37.6735,KLD Loss:  20.8559\n",
      "Epoch 59, Reconstruct Loss: -41.0698,KLD Loss:  20.7673\n",
      "Epoch 60, Reconstruct Loss: -40.8181,KLD Loss:  20.6817\n",
      "Epoch 61, Reconstruct Loss: -29.7356,KLD Loss:  20.5909\n",
      "Epoch 62, Reconstruct Loss: -24.0171,KLD Loss:  20.4114\n",
      "Epoch 63, Reconstruct Loss: -40.0146,KLD Loss:  20.2668\n",
      "Epoch 64, Reconstruct Loss: -39.7631,KLD Loss:  20.0952\n",
      "Epoch 65, Reconstruct Loss: -36.4905,KLD Loss:  19.9019\n",
      "Epoch 66, Reconstruct Loss: -29.3388,KLD Loss:  19.7305\n",
      "Epoch 67, Reconstruct Loss: -32.4927,KLD Loss:  19.5708\n",
      "Epoch 68, Reconstruct Loss: -39.7713,KLD Loss:  19.4569\n",
      "Epoch 69, Reconstruct Loss: -36.8622,KLD Loss:  19.3960\n",
      "Epoch 70, Reconstruct Loss: -33.9804,KLD Loss:  19.3177\n",
      "Epoch 71, Reconstruct Loss: -36.3244,KLD Loss:  19.2978\n",
      "Epoch 72, Reconstruct Loss: -29.5503,KLD Loss:  19.2406\n",
      "Epoch 73, Reconstruct Loss: -34.7680,KLD Loss:  19.1093\n",
      "Epoch 74, Reconstruct Loss: -40.8479,KLD Loss:  18.9671\n",
      "Epoch 75, Reconstruct Loss: -33.6097,KLD Loss:  18.8339\n",
      "Epoch 76, Reconstruct Loss: -39.2346,KLD Loss:  18.7884\n",
      "Epoch 77, Reconstruct Loss: -40.4665,KLD Loss:  18.7549\n",
      "Epoch 78, Reconstruct Loss: -41.7043,KLD Loss:  18.7285\n",
      "Epoch 79, Reconstruct Loss: -38.2000,KLD Loss:  18.6773\n",
      "Epoch 80, Reconstruct Loss: -37.6263,KLD Loss:  18.6171\n",
      "Epoch 81, Reconstruct Loss: -34.9185,KLD Loss:  18.5249\n",
      "Epoch 82, Reconstruct Loss: -40.6384,KLD Loss:  18.4211\n",
      "Epoch 83, Reconstruct Loss: -41.8230,KLD Loss:  18.3211\n",
      "Epoch 84, Reconstruct Loss: -34.6213,KLD Loss:  18.2128\n",
      "Epoch 85, Reconstruct Loss: -42.8275,KLD Loss:  18.1393\n",
      "Epoch 86, Reconstruct Loss: -39.3506,KLD Loss:  18.0296\n",
      "Epoch 87, Reconstruct Loss: -39.7118,KLD Loss:  17.9793\n",
      "Epoch 88, Reconstruct Loss: -41.4992,KLD Loss:  17.9559\n",
      "Epoch 89, Reconstruct Loss: -42.5854,KLD Loss:  17.8786\n",
      "Epoch 90, Reconstruct Loss: -41.1356,KLD Loss:  17.7898\n",
      "Epoch 91, Reconstruct Loss: -37.5640,KLD Loss:  17.7141\n",
      "Epoch 92, Reconstruct Loss: -42.1777,KLD Loss:  17.6386\n",
      "Epoch 93, Reconstruct Loss: -41.1076,KLD Loss:  17.5148\n",
      "Epoch 94, Reconstruct Loss: -42.8302,KLD Loss:  17.3893\n",
      "Epoch 95, Reconstruct Loss: -43.2606,KLD Loss:  17.2311\n",
      "Epoch 96, Reconstruct Loss: -39.8251,KLD Loss:  17.0676\n",
      "Epoch 97, Reconstruct Loss: -42.2331,KLD Loss:  16.9258\n",
      "Epoch 98, Reconstruct Loss: -39.6168,KLD Loss:  16.8013\n",
      "Epoch 99, Reconstruct Loss: -42.4822,KLD Loss:  16.7075\n",
      "Epoch 100, Reconstruct Loss: -42.9858,KLD Loss:  16.6132\n",
      "Epoch 101, Reconstruct Loss: -40.4493,KLD Loss:  16.5311\n",
      "Epoch 102, Reconstruct Loss: -42.3726,KLD Loss:  16.4583\n",
      "Epoch 103, Reconstruct Loss: -43.1456,KLD Loss:  16.3550\n",
      "Epoch 104, Reconstruct Loss: -37.3273,KLD Loss:  16.2578\n",
      "Epoch 105, Reconstruct Loss: -39.0251,KLD Loss:  16.0923\n",
      "Epoch 106, Reconstruct Loss: -44.2922,KLD Loss:  15.9755\n",
      "Epoch 107, Reconstruct Loss: -44.0052,KLD Loss:  15.8298\n",
      "Epoch 108, Reconstruct Loss: -39.3176,KLD Loss:  15.6886\n",
      "Epoch 109, Reconstruct Loss: -40.0146,KLD Loss:  15.6024\n",
      "Epoch 110, Reconstruct Loss: -41.5970,KLD Loss:  15.5590\n",
      "Epoch 111, Reconstruct Loss: -44.3044,KLD Loss:  15.5336\n",
      "Epoch 112, Reconstruct Loss: -42.6283,KLD Loss:  15.4737\n",
      "Epoch 113, Reconstruct Loss: -32.2710,KLD Loss:  15.4483\n",
      "Epoch 114, Reconstruct Loss: -34.6696,KLD Loss:  15.5686\n",
      "Epoch 115, Reconstruct Loss: -35.0708,KLD Loss:  15.7045\n",
      "Epoch 116, Reconstruct Loss: -40.4006,KLD Loss:  15.7947\n",
      "Epoch 117, Reconstruct Loss: -37.3513,KLD Loss:  15.8593\n",
      "Epoch 118, Reconstruct Loss: -41.0659,KLD Loss:  15.8361\n",
      "Epoch 119, Reconstruct Loss: -35.8765,KLD Loss:  15.7576\n",
      "Epoch 120, Reconstruct Loss: -37.7560,KLD Loss:  15.6709\n",
      "Epoch 121, Reconstruct Loss: -43.2869,KLD Loss:  15.5575\n",
      "Epoch 122, Reconstruct Loss: -37.2173,KLD Loss:  15.4770\n",
      "Epoch 123, Reconstruct Loss: -29.5463,KLD Loss:  15.3999\n",
      "Epoch 124, Reconstruct Loss: -35.7847,KLD Loss:  15.2992\n",
      "Epoch 125, Reconstruct Loss: -35.3846,KLD Loss:  15.2485\n",
      "Epoch 126, Reconstruct Loss: -40.7236,KLD Loss:  15.2099\n",
      "Epoch 127, Reconstruct Loss: -30.6191,KLD Loss:  15.1787\n",
      "Epoch 128, Reconstruct Loss: -41.3339,KLD Loss:  15.1899\n",
      "Epoch 129, Reconstruct Loss: -41.9932,KLD Loss:  15.1603\n",
      "Epoch 130, Reconstruct Loss: -39.8620,KLD Loss:  15.1652\n",
      "Epoch 131, Reconstruct Loss: -36.6772,KLD Loss:  15.1214\n",
      "Epoch 132, Reconstruct Loss: -42.1435,KLD Loss:  15.0826\n",
      "Epoch 133, Reconstruct Loss: -40.7789,KLD Loss:  15.0457\n",
      "Epoch 134, Reconstruct Loss: -38.5818,KLD Loss:  14.9718\n",
      "Epoch 135, Reconstruct Loss: -40.7790,KLD Loss:  14.8657\n",
      "Epoch 136, Reconstruct Loss: -38.4983,KLD Loss:  14.7850\n",
      "Epoch 137, Reconstruct Loss: -41.5787,KLD Loss:  14.7580\n",
      "Epoch 138, Reconstruct Loss: -39.4516,KLD Loss:  14.7332\n",
      "Epoch 139, Reconstruct Loss: -42.0883,KLD Loss:  14.7569\n",
      "Epoch 140, Reconstruct Loss: -44.3186,KLD Loss:  14.7515\n",
      "Epoch 141, Reconstruct Loss: -44.7885,KLD Loss:  14.7523\n",
      "Epoch 142, Reconstruct Loss: -38.5907,KLD Loss:  14.7336\n",
      "Epoch 143, Reconstruct Loss: -42.0643,KLD Loss:  14.7545\n",
      "Epoch 144, Reconstruct Loss: -43.6445,KLD Loss:  14.7920\n",
      "Epoch 145, Reconstruct Loss: -40.3366,KLD Loss:  14.8006\n",
      "Epoch 146, Reconstruct Loss: -37.6118,KLD Loss:  14.7750\n",
      "Epoch 147, Reconstruct Loss: -39.3432,KLD Loss:  14.7008\n",
      "Epoch 148, Reconstruct Loss: -35.4468,KLD Loss:  14.6267\n",
      "Epoch 149, Reconstruct Loss: -42.4739,KLD Loss:  14.5858\n",
      "Epoch 150, Reconstruct Loss: -39.9077,KLD Loss:  14.5398\n",
      "Epoch 151, Reconstruct Loss: -22.8509,KLD Loss:  14.5309\n",
      "Epoch 152, Reconstruct Loss: -39.5444,KLD Loss:  14.6766\n",
      "Epoch 153, Reconstruct Loss: -39.5406,KLD Loss:  14.8141\n",
      "Epoch 154, Reconstruct Loss: -40.2670,KLD Loss:  14.9386\n",
      "Epoch 155, Reconstruct Loss: -43.3892,KLD Loss:  14.9992\n",
      "Epoch 156, Reconstruct Loss: -43.7051,KLD Loss:  15.0018\n",
      "Epoch 157, Reconstruct Loss: -32.7472,KLD Loss:  14.9594\n",
      "Epoch 158, Reconstruct Loss: -44.2137,KLD Loss:  15.0571\n",
      "Epoch 159, Reconstruct Loss: -36.7763,KLD Loss:  15.1203\n",
      "Epoch 160, Reconstruct Loss: -37.7335,KLD Loss:  15.1590\n",
      "Epoch 161, Reconstruct Loss: -41.3830,KLD Loss:  15.2013\n",
      "Epoch 162, Reconstruct Loss: -41.1147,KLD Loss:  15.2608\n",
      "Epoch 163, Reconstruct Loss: -40.2469,KLD Loss:  15.3358\n",
      "Epoch 164, Reconstruct Loss: -28.1859,KLD Loss:  15.3847\n",
      "Epoch 165, Reconstruct Loss: -26.1398,KLD Loss:  15.4296\n",
      "Epoch 166, Reconstruct Loss: -40.6850,KLD Loss:  15.4714\n",
      "Epoch 167, Reconstruct Loss: -42.1441,KLD Loss:  15.4880\n",
      "Epoch 168, Reconstruct Loss: -43.1087,KLD Loss:  15.4733\n",
      "Epoch 169, Reconstruct Loss: -35.6750,KLD Loss:  15.4199\n",
      "Epoch 170, Reconstruct Loss: -42.5031,KLD Loss:  15.3980\n",
      "Epoch 171, Reconstruct Loss: -42.4294,KLD Loss:  15.3397\n",
      "Epoch 172, Reconstruct Loss: -42.6973,KLD Loss:  15.2716\n",
      "Epoch 173, Reconstruct Loss: -44.1361,KLD Loss:  15.2048\n",
      "Epoch 174, Reconstruct Loss: -41.1540,KLD Loss:  15.1340\n",
      "Epoch 175, Reconstruct Loss: -38.9144,KLD Loss:  15.0519\n",
      "Epoch 176, Reconstruct Loss: -35.8734,KLD Loss:  15.0424\n",
      "Epoch 177, Reconstruct Loss: -34.8790,KLD Loss:  15.1440\n",
      "Epoch 178, Reconstruct Loss: -38.7066,KLD Loss:  15.2983\n",
      "Epoch 179, Reconstruct Loss: -36.9973,KLD Loss:  15.4165\n",
      "Epoch 180, Reconstruct Loss: -37.6104,KLD Loss:  15.5429\n",
      "Epoch 181, Reconstruct Loss: -38.5585,KLD Loss:  15.5984\n",
      "Epoch 182, Reconstruct Loss: -41.8493,KLD Loss:  15.5906\n",
      "Epoch 183, Reconstruct Loss: -44.7052,KLD Loss:  15.5477\n",
      "Epoch 184, Reconstruct Loss: -42.1644,KLD Loss:  15.4938\n",
      "Epoch 185, Reconstruct Loss: -38.1011,KLD Loss:  15.4141\n",
      "Epoch 186, Reconstruct Loss: -41.2298,KLD Loss:  15.3144\n",
      "Epoch 187, Reconstruct Loss: -25.9590,KLD Loss:  15.2097\n",
      "Epoch 188, Reconstruct Loss: -40.3584,KLD Loss:  15.1907\n",
      "Epoch 189, Reconstruct Loss: -35.8915,KLD Loss:  15.1808\n",
      "Epoch 190, Reconstruct Loss: -42.8287,KLD Loss:  15.1609\n",
      "Epoch 191, Reconstruct Loss: -42.4986,KLD Loss:  15.1216\n",
      "Epoch 192, Reconstruct Loss: -41.3708,KLD Loss:  15.0949\n",
      "Epoch 193, Reconstruct Loss: -38.1861,KLD Loss:  15.0482\n",
      "Epoch 194, Reconstruct Loss: -39.7034,KLD Loss:  14.9682\n",
      "Epoch 195, Reconstruct Loss: -44.2556,KLD Loss:  14.8395\n",
      "Epoch 196, Reconstruct Loss: -26.7514,KLD Loss:  14.6837\n",
      "Epoch 197, Reconstruct Loss: -39.8422,KLD Loss:  14.6315\n",
      "Epoch 198, Reconstruct Loss: -41.0943,KLD Loss:  14.5961\n",
      "Epoch 199, Reconstruct Loss: -43.4961,KLD Loss:  14.5543\n",
      "Epoch 200, Reconstruct Loss: -37.5005,KLD Loss:  14.5074\n",
      "Epoch 201, Reconstruct Loss: -38.8968,KLD Loss:  14.4710\n",
      "Epoch 202, Reconstruct Loss: -40.1713,KLD Loss:  14.4351\n",
      "Epoch 203, Reconstruct Loss: -42.5190,KLD Loss:  14.4307\n",
      "Epoch 204, Reconstruct Loss: -40.7743,KLD Loss:  14.4296\n",
      "Epoch 205, Reconstruct Loss: -43.8023,KLD Loss:  14.4529\n",
      "Epoch 206, Reconstruct Loss: -38.7642,KLD Loss:  14.4293\n",
      "Epoch 207, Reconstruct Loss: -39.8274,KLD Loss:  14.4355\n",
      "Epoch 208, Reconstruct Loss: -40.9494,KLD Loss:  14.4077\n",
      "Epoch 209, Reconstruct Loss: -41.5110,KLD Loss:  14.3353\n",
      "Epoch 210, Reconstruct Loss: -43.0439,KLD Loss:  14.2812\n",
      "Epoch 211, Reconstruct Loss: -45.6553,KLD Loss:  14.2315\n",
      "Epoch 212, Reconstruct Loss: -33.9146,KLD Loss:  14.1556\n",
      "Epoch 213, Reconstruct Loss: -38.9382,KLD Loss:  14.1679\n",
      "Epoch 214, Reconstruct Loss: -43.4078,KLD Loss:  14.1914\n",
      "Epoch 215, Reconstruct Loss: -43.8906,KLD Loss:  14.2057\n",
      "Epoch 216, Reconstruct Loss: -43.8359,KLD Loss:  14.1950\n",
      "Epoch 217, Reconstruct Loss: -41.4402,KLD Loss:  14.1428\n",
      "Epoch 218, Reconstruct Loss: -43.1915,KLD Loss:  14.0891\n",
      "Epoch 219, Reconstruct Loss: -36.1168,KLD Loss:  14.0179\n",
      "Epoch 220, Reconstruct Loss: -42.7594,KLD Loss:  13.9926\n",
      "Epoch 221, Reconstruct Loss: -45.0365,KLD Loss:  13.9709\n",
      "Epoch 222, Reconstruct Loss: -41.8959,KLD Loss:  13.9157\n",
      "Epoch 223, Reconstruct Loss: -38.8065,KLD Loss:  13.8249\n",
      "Epoch 224, Reconstruct Loss: -44.6548,KLD Loss:  13.6952\n",
      "Epoch 225, Reconstruct Loss: -39.2435,KLD Loss:  13.5483\n",
      "Epoch 226, Reconstruct Loss: -43.5868,KLD Loss:  13.4156\n",
      "Epoch 227, Reconstruct Loss: -39.0320,KLD Loss:  13.2849\n",
      "Epoch 228, Reconstruct Loss: -43.0357,KLD Loss:  13.1932\n",
      "Epoch 229, Reconstruct Loss: -35.9676,KLD Loss:  13.1154\n",
      "Epoch 230, Reconstruct Loss: -34.2673,KLD Loss:  13.0362\n",
      "Epoch 231, Reconstruct Loss: -44.6152,KLD Loss:  12.9796\n",
      "Epoch 232, Reconstruct Loss: -41.8443,KLD Loss:  12.9093\n",
      "Epoch 233, Reconstruct Loss: -33.1827,KLD Loss:  12.8467\n",
      "Epoch 234, Reconstruct Loss: -42.2195,KLD Loss:  12.8786\n",
      "Epoch 235, Reconstruct Loss: -25.3660,KLD Loss:  12.9062\n",
      "Epoch 236, Reconstruct Loss: -29.8286,KLD Loss:  12.8816\n",
      "Epoch 237, Reconstruct Loss: -42.8372,KLD Loss:  12.8846\n",
      "Epoch 238, Reconstruct Loss: -44.0357,KLD Loss:  12.8988\n",
      "Epoch 239, Reconstruct Loss: -29.7431,KLD Loss:  12.9000\n",
      "Epoch 240, Reconstruct Loss: -42.0750,KLD Loss:  12.9180\n",
      "Epoch 241, Reconstruct Loss: -41.8725,KLD Loss:  12.9227\n",
      "Epoch 242, Reconstruct Loss: -36.1776,KLD Loss:  12.9531\n",
      "Epoch 243, Reconstruct Loss: -35.4127,KLD Loss:  13.0113\n",
      "Epoch 244, Reconstruct Loss: -31.6638,KLD Loss:  13.1081\n",
      "Epoch 245, Reconstruct Loss: -39.3814,KLD Loss:  13.2298\n",
      "Epoch 246, Reconstruct Loss: -39.6716,KLD Loss:  13.3253\n",
      "Epoch 247, Reconstruct Loss: -42.3125,KLD Loss:  13.3851\n",
      "Epoch 248, Reconstruct Loss: -42.1126,KLD Loss:  13.3988\n",
      "Epoch 249, Reconstruct Loss: -41.8861,KLD Loss:  13.3745\n",
      "Epoch 250, Reconstruct Loss: -43.6183,KLD Loss:  13.3408\n",
      "Epoch 251, Reconstruct Loss: -40.2256,KLD Loss:  13.3030\n",
      "Epoch 252, Reconstruct Loss: -42.0302,KLD Loss:  13.2526\n",
      "Epoch 253, Reconstruct Loss: -40.6245,KLD Loss:  13.1779\n",
      "Epoch 254, Reconstruct Loss: -37.7551,KLD Loss:  13.0918\n",
      "Epoch 255, Reconstruct Loss: -44.4213,KLD Loss:  13.0047\n",
      "Epoch 256, Reconstruct Loss: -43.2016,KLD Loss:  12.9025\n",
      "Epoch 257, Reconstruct Loss: -41.7285,KLD Loss:  12.8038\n",
      "Epoch 258, Reconstruct Loss: -37.5306,KLD Loss:  12.7303\n",
      "Epoch 259, Reconstruct Loss: -39.6813,KLD Loss:  12.6956\n",
      "Epoch 260, Reconstruct Loss: -37.3836,KLD Loss:  12.6649\n",
      "Epoch 261, Reconstruct Loss: -42.0390,KLD Loss:  12.6320\n",
      "Epoch 262, Reconstruct Loss: -37.2130,KLD Loss:  12.5980\n",
      "Epoch 263, Reconstruct Loss: -40.8315,KLD Loss:  12.5370\n",
      "Epoch 264, Reconstruct Loss: -39.8575,KLD Loss:  12.5051\n",
      "Epoch 265, Reconstruct Loss: -33.0695,KLD Loss:  12.4633\n",
      "Epoch 266, Reconstruct Loss: -43.3945,KLD Loss:  12.4351\n",
      "Epoch 267, Reconstruct Loss: -41.1704,KLD Loss:  12.3934\n",
      "Epoch 268, Reconstruct Loss: -42.3362,KLD Loss:  12.3299\n",
      "Epoch 269, Reconstruct Loss: -36.8958,KLD Loss:  12.2597\n",
      "Epoch 270, Reconstruct Loss: -37.6745,KLD Loss:  12.1701\n",
      "Epoch 271, Reconstruct Loss: -42.8216,KLD Loss:  12.1071\n",
      "Epoch 272, Reconstruct Loss: -42.6565,KLD Loss:  12.0575\n",
      "Epoch 273, Reconstruct Loss: -42.4736,KLD Loss:  11.9989\n",
      "Epoch 274, Reconstruct Loss: -40.5980,KLD Loss:  11.9347\n",
      "Epoch 275, Reconstruct Loss: -42.3143,KLD Loss:  11.8661\n",
      "Epoch 276, Reconstruct Loss: -24.9699,KLD Loss:  11.8207\n",
      "Epoch 277, Reconstruct Loss: -37.8643,KLD Loss:  11.9816\n",
      "Epoch 278, Reconstruct Loss: -42.5547,KLD Loss:  12.1299\n",
      "Epoch 279, Reconstruct Loss: -43.1465,KLD Loss:  12.2587\n",
      "Epoch 280, Reconstruct Loss: -42.5249,KLD Loss:  12.3917\n",
      "Epoch 281, Reconstruct Loss: -38.5368,KLD Loss:  12.5193\n",
      "Epoch 282, Reconstruct Loss: -38.0062,KLD Loss:  12.6701\n",
      "Epoch 283, Reconstruct Loss: -37.7858,KLD Loss:  12.7757\n",
      "Epoch 284, Reconstruct Loss: -38.8984,KLD Loss:  12.8694\n",
      "Epoch 285, Reconstruct Loss: -42.8632,KLD Loss:  12.9222\n",
      "Epoch 286, Reconstruct Loss: -14.1829,KLD Loss:  12.9582\n",
      "Epoch 287, Reconstruct Loss: -44.3651,KLD Loss:  13.0757\n",
      "Epoch 288, Reconstruct Loss: -44.1325,KLD Loss:  13.1918\n",
      "Epoch 289, Reconstruct Loss: -39.9667,KLD Loss:  13.2884\n",
      "Epoch 290, Reconstruct Loss: -39.3249,KLD Loss:  13.3753\n",
      "Epoch 291, Reconstruct Loss: -42.1458,KLD Loss:  13.4775\n",
      "Epoch 292, Reconstruct Loss: -43.0610,KLD Loss:  13.5795\n",
      "Epoch 293, Reconstruct Loss: -33.5726,KLD Loss:  13.6719\n",
      "Epoch 294, Reconstruct Loss: -38.2843,KLD Loss:  13.8160\n",
      "Epoch 295, Reconstruct Loss: -41.7974,KLD Loss:  13.8951\n",
      "Epoch 296, Reconstruct Loss: -38.4389,KLD Loss:  13.9399\n",
      "Epoch 297, Reconstruct Loss: -39.1812,KLD Loss:  13.9321\n",
      "Epoch 298, Reconstruct Loss: -42.6225,KLD Loss:  13.9021\n",
      "Epoch 299, Reconstruct Loss: -41.4808,KLD Loss:  13.8442\n",
      "Epoch 300, Reconstruct Loss: -41.1159,KLD Loss:  13.7802\n",
      "filter_mask :  True\n",
      "len filtered_df : 4148\n",
      "df_combined : 10\n"
     ]
    }
   ],
   "source": [
    "pipeline_builder = PipelineBuilder(df_real_adult_train, cat_list_adult, num_list_adult, ctgan)\n",
    "pipeline_builder.add_generation_task()\n",
    "pipeline_builder.add_fine_tuning_generation_task()\n",
    "# pipeline_builder.add_sampling_and_reject_task(0.1)\n",
    "pipeline_builder.add_ressemblance_evaluation_task(df_real_adult_test)\n",
    "pipeline = pipeline_builder.build()\n",
    "synth = pipeline_builder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation_results': {'synthetic_data':        age workclass  fnlwgt      education  education-num  \\\n",
       "  0       20   Private   44905        HS-grad              9   \n",
       "  1       32   Private  109852        HS-grad              9   \n",
       "  2       38   Private  124729        HS-grad              9   \n",
       "  3       23   Private   52677      Bachelors             13   \n",
       "  4       41   Private  138111        HS-grad              9   \n",
       "  ...    ...       ...     ...            ...            ...   \n",
       "  32556   32   Private   27882           10th             10   \n",
       "  32557   32   Private   27882   Some-college             10   \n",
       "  32558   32   Private   27882   Some-college             10   \n",
       "  32559   32   Private   27882   Some-college             10   \n",
       "  32560   32   Private   27882   Some-college             10   \n",
       "  \n",
       "              marital-status          occupation     relationship    race  \\\n",
       "  0            Never-married               Sales        Own-child   White   \n",
       "  1       Married-civ-spouse   Handlers-cleaners          Husband   Black   \n",
       "  2       Married-civ-spouse     Exec-managerial          Husband   White   \n",
       "  3            Never-married      Prof-specialty    Not-in-family   White   \n",
       "  4       Married-civ-spouse      Prof-specialty          Husband   White   \n",
       "  ...                    ...                 ...              ...     ...   \n",
       "  32556        Never-married   Machine-op-inspct   Other-relative   White   \n",
       "  32557        Never-married               Sales   Other-relative   White   \n",
       "  32558        Never-married   Machine-op-inspct   Other-relative   White   \n",
       "  32559        Never-married       Other-service   Other-relative   White   \n",
       "  32560   Married-civ-spouse   Machine-op-inspct   Other-relative   White   \n",
       "  \n",
       "             sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "  0       Female             0             0              22   \n",
       "  1         Male             1             0              40   \n",
       "  2         Male             0             0              48   \n",
       "  3       Female             0             0              40   \n",
       "  4         Male             4             0              50   \n",
       "  ...        ...           ...           ...             ...   \n",
       "  32556   Female             0          2205              40   \n",
       "  32557   Female             0          2205              40   \n",
       "  32558   Female             0          2205              40   \n",
       "  32559   Female             0          2205              40   \n",
       "  32560   Female             0          2205              40   \n",
       "  \n",
       "              native-country  income  \n",
       "  0            United-States   <=50K  \n",
       "  1            United-States   <=50K  \n",
       "  2            United-States   <=50K  \n",
       "  3            United-States   <=50K  \n",
       "  4            United-States   <=50K  \n",
       "  ...                    ...     ...  \n",
       "  32556   Holand-Netherlands   <=50K  \n",
       "  32557   Holand-Netherlands   <=50K  \n",
       "  32558   Holand-Netherlands   <=50K  \n",
       "  32559   Holand-Netherlands   <=50K  \n",
       "  32560   Holand-Netherlands   <=50K  \n",
       "  \n",
       "  [32561 rows x 15 columns],\n",
       "  'generator_model': <data_synthesizer.sdv.tvae.tvae_synthesizer_modified.SDVTVAE_ at 0x7fe5196491c0>},\n",
       " 'resemblance_evaluation_results': {'categorical_univariate': {'chi_test':                 chisquared_tests_p\n",
       "   workclass                 0.663443\n",
       "   education                 0.874721\n",
       "   marital-status            0.806358\n",
       "   occupation                0.432468\n",
       "   relationship              0.492932\n",
       "   race                      0.968939\n",
       "   sex                       0.911645\n",
       "   native-country            0.573853\n",
       "   income                    0.940006,\n",
       "   'jensen_shanon':                 KL_divergence_tests  JS_divergence\n",
       "   workclass                  0.007966       0.052401\n",
       "   education                  0.037411       0.110197\n",
       "   marital-status             0.014824       0.067782\n",
       "   occupation                 0.021422       0.086315\n",
       "   relationship               0.027059       0.096898\n",
       "   race                       0.035106       0.083255\n",
       "   sex                        0.001707       0.024891\n",
       "   native-country             0.095857       0.141772\n",
       "   income                     0.000137       0.007020,\n",
       "   'jensen_shanon_data_mean': KL_divergence_tests    0.026832\n",
       "   JS_divergence          0.074503\n",
       "   dtype: float64,\n",
       "   'mode_collapse_dict': {}},\n",
       "  'numerical_univariate': {'univariate_num_s':                 mann_whitney      wilcoxon     student_t  welchs_Ttest  \\\n",
       "   age             1.924351e-02  8.475609e-04  1.211809e-05  1.211818e-05   \n",
       "   fnlwgt          0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "   education-num   8.131592e-07  1.275480e-09  3.688187e-10  3.688189e-10   \n",
       "   capital-gain    0.000000e+00  0.000000e+00  6.076439e-57  7.328389e-57   \n",
       "   capital-loss    9.693900e-07  3.830946e-27  1.586940e-29  1.592546e-29   \n",
       "   hours-per-week  1.467847e-04  4.653097e-13  1.310696e-21  1.313909e-21   \n",
       "   \n",
       "                      ks_test_p  \n",
       "   age             1.258055e-25  \n",
       "   fnlwgt          0.000000e+00  \n",
       "   education-num   2.722511e-26  \n",
       "   capital-gain    0.000000e+00  \n",
       "   capital-loss    1.648884e-04  \n",
       "   hours-per-week  2.582010e-83  ,\n",
       "   'univariate_num_js':                 KL_divergence_tests  JS_divergence  cohen_s_d\n",
       "   age                        0.374782       0.104917   0.034294\n",
       "   fnlwgt                     0.000706       0.442329   0.891870\n",
       "   education-num              1.351798       0.085247   0.049121\n",
       "   capital-gain               0.011366       0.560898   0.124755\n",
       "   capital-loss               0.019618       0.174464   0.088474\n",
       "   hours-per-week             2.011323       0.212032   0.074864,\n",
       "   'univariate_num_js_data_mean': KL_divergence_tests    0.628266\n",
       "   JS_divergence          0.263314\n",
       "   cohen_s_d              0.210563\n",
       "   dtype: float64},\n",
       "  'categorical_multivariate': {'cramer_real':                 workclass  education  marital-status  occupation  \\\n",
       "   workclass        1.000000   0.099369        0.085061    0.399993   \n",
       "   education        0.099369   1.000000        0.091569    0.187334   \n",
       "   marital-status   0.085061   0.091569        1.000000    0.133213   \n",
       "   occupation       0.399993   0.187334        0.133213    1.000000   \n",
       "   relationship     0.098712   0.122654        0.487963    0.178626   \n",
       "   race             0.056280   0.074900        0.084219    0.080826   \n",
       "   sex              0.153670   0.095621        0.461827    0.424364   \n",
       "   native-country   0.045810   0.132637        0.073070    0.073121   \n",
       "   income           0.179208   0.368838        0.447404    0.351892   \n",
       "   \n",
       "                   relationship      race       sex  native-country    income  \n",
       "   workclass           0.098712  0.056280  0.153670        0.045810  0.179208  \n",
       "   education           0.122654  0.074900  0.095621        0.132637  0.368838  \n",
       "   marital-status      0.487963  0.084219  0.461827        0.073070  0.447404  \n",
       "   occupation          0.178626  0.080826  0.424364        0.073121  0.351892  \n",
       "   relationship        1.000000  0.098099  0.649000        0.085310  0.453585  \n",
       "   race                0.098099  1.000000  0.118115        0.409258  0.100812  \n",
       "   sex                 0.649000  0.118115  1.000000        0.067148  0.215980  \n",
       "   native-country      0.085310  0.409258  0.067148        1.000000  0.098705  \n",
       "   income              0.453585  0.100812  0.215980        0.098705  1.000000  ,\n",
       "   'cramer_synth':                 workclass  education  marital-status  occupation  \\\n",
       "   workclass        1.000000   0.093561        0.072000    0.350258   \n",
       "   education        0.093561   1.000000        0.050315    0.166986   \n",
       "   marital-status   0.072000   0.050315        1.000000    0.120985   \n",
       "   occupation       0.350258   0.166986        0.120985    1.000000   \n",
       "   relationship     0.091557   0.077091        0.487057    0.183109   \n",
       "   race             0.054393   0.086249        0.120559    0.107550   \n",
       "   sex              0.145651   0.047797        0.344349    0.457272   \n",
       "   native-country   0.066475   0.116545        0.100417    0.077010   \n",
       "   income           0.186748   0.225541        0.484353    0.324519   \n",
       "   \n",
       "                   relationship      race       sex  native-country    income  \n",
       "   workclass           0.091557  0.054393  0.145651        0.066475  0.186748  \n",
       "   education           0.077091  0.086249  0.047797        0.116545  0.225541  \n",
       "   marital-status      0.487057  0.120559  0.344349        0.100417  0.484353  \n",
       "   occupation          0.183109  0.107550  0.457272        0.077010  0.324519  \n",
       "   relationship        1.000000  0.140095  0.652297        0.148768  0.497253  \n",
       "   race                0.140095  1.000000  0.176388        0.382465  0.073804  \n",
       "   sex                 0.652297  0.176388  1.000000        0.075640  0.176121  \n",
       "   native-country      0.148768  0.382465  0.075640        1.000000  0.070524  \n",
       "   income              0.497253  0.073804  0.176121        0.070524  1.000000  ,\n",
       "   'diff_norm_cramer': 0.039899999999999824},\n",
       "  'numerical_multivariate': {'pearson_real':                      age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "   age             1.000000  0.076646       0.036527      0.077674      0.057775   \n",
       "   fnlwgt          0.076646  1.000000       0.043195      0.000432      0.010252   \n",
       "   education-num   0.036527  0.043195       1.000000      0.122630      0.079923   \n",
       "   capital-gain    0.077674  0.000432       0.122630      1.000000      0.031615   \n",
       "   capital-loss    0.057775  0.010252       0.079923      0.031615      1.000000   \n",
       "   hours-per-week  0.068756  0.018768       0.148123      0.078409      0.054256   \n",
       "   \n",
       "                   hours-per-week  \n",
       "   age                   0.068756  \n",
       "   fnlwgt                0.018768  \n",
       "   education-num         0.148123  \n",
       "   capital-gain          0.078409  \n",
       "   capital-loss          0.054256  \n",
       "   hours-per-week        1.000000  ,\n",
       "   'pearson_synth':                      age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "   age             1.000000  0.144761       0.012873      0.075985      0.072715   \n",
       "   fnlwgt          0.144761  1.000000       0.007829      0.010505      0.089183   \n",
       "   education-num   0.012873  0.007829       1.000000      0.071749      0.011874   \n",
       "   capital-gain    0.075985  0.010505       0.071749      1.000000      0.027517   \n",
       "   capital-loss    0.072715  0.089183       0.011874      0.027517      1.000000   \n",
       "   hours-per-week  0.120359  0.036335       0.082608      0.065418      0.035307   \n",
       "   \n",
       "                   hours-per-week  \n",
       "   age                   0.120359  \n",
       "   fnlwgt                0.036335  \n",
       "   education-num         0.082608  \n",
       "   capital-gain          0.065418  \n",
       "   capital-loss          0.035307  \n",
       "   hours-per-week        1.000000  ,\n",
       "   'pearson_norm_diff': 0.001100000000000101},\n",
       "  'categorical_numerical_multivariate': {'corr_ratio_real': {'corr':                 workclass  education  marital-status  occupation  \\\n",
       "    age              0.218365   0.229077        0.573546    0.186472   \n",
       "    fnlwgt           0.052620   0.067111        0.054406    0.055344   \n",
       "    education-num    0.197346   1.000000        0.115492    0.556586   \n",
       "    capital-gain     0.104268   0.197873        0.087206    0.119566   \n",
       "    capital-loss     0.046975   0.099203        0.081717    0.085112   \n",
       "    hours-per-week   0.228189   0.194284        0.250627    0.311444   \n",
       "    \n",
       "                    relationship      race       sex  native-country    income  \n",
       "    age                 0.474219  0.043588  0.088832        0.088367  0.234037  \n",
       "    fnlwgt              0.037277  0.140456  0.026858        0.158627  0.009463  \n",
       "    education-num       0.160911  0.109650  0.012280        0.276936  0.335154  \n",
       "    capital-gain        0.090418  0.023410  0.048480        0.035641  0.223329  \n",
       "    capital-loss        0.087701  0.026708  0.045567        0.053354  0.150526  \n",
       "    hours-per-week      0.310074  0.054680  0.229309        0.048591  0.229689  ,\n",
       "    'ax': <Axes: >},\n",
       "   'corr_ratio_synth': {'corr':                 workclass  education  marital-status  occupation  \\\n",
       "    age              0.231483   0.160350        0.582745    0.212655   \n",
       "    fnlwgt           0.141478   0.123046        0.095628    0.203283   \n",
       "    education-num    0.161372   0.910828        0.062030    0.503459   \n",
       "    capital-gain     0.045962   0.079873        0.112441    0.114369   \n",
       "    capital-loss     0.030259   0.028562        0.059279    0.059744   \n",
       "    hours-per-week   0.163640   0.117779        0.256207    0.316663   \n",
       "    \n",
       "                    relationship      race       sex  native-country    income  \n",
       "    age                 0.505063  0.091423  0.089703        0.070651  0.286394  \n",
       "    fnlwgt              0.153811  0.115747  0.020055        0.167372  0.027947  \n",
       "    education-num       0.104956  0.113127  0.035042        0.186428  0.197673  \n",
       "    capital-gain        0.113418  0.023649  0.008948        0.044806  0.228323  \n",
       "    capital-loss        0.062071  0.045049  0.026864        0.124289  0.077269  \n",
       "    hours-per-week      0.338173  0.044389  0.285820        0.051715  0.215548  ,\n",
       "    'ax': <Axes: >},\n",
       "   'diff_norm_corr_ratio': 0.08319999999999994}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_builder.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education-num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital-status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "       income  \n",
       "0       <=50K  \n",
       "1       <=50K  \n",
       "2       <=50K  \n",
       "3       <=50K  \n",
       "4       <=50K  \n",
       "...       ...  \n",
       "32556   <=50K  \n",
       "32557    >50K  \n",
       "32558   <=50K  \n",
       "32559   <=50K  \n",
       "32560    >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_real_adult_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i, child in enumerate(model._model.encoder.seq.children()):\n",
    "    if i < 2:\n",
    "        for param in child.parameters():\n",
    "            print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'generation_results': {'synthetic_data':        age     workclass  fnlwgt      education  education-num  \\\n",
       "  0       44       Private  395942        HS-grad              7   \n",
       "  1       56     State-gov  207793   Some-college             12   \n",
       "  2       40       Private   96988        HS-grad             11   \n",
       "  3       43   Federal-gov   52352   Some-college              5   \n",
       "  4       39       Private   45930   Some-college             14   \n",
       "  ...    ...           ...     ...            ...            ...   \n",
       "  32556   58       Private   26258   Some-college             13   \n",
       "  32557   27   Federal-gov  172852   Some-college             14   \n",
       "  32558   31       Private  634264        HS-grad             10   \n",
       "  32559   72       Private   76253   Some-college              9   \n",
       "  32560   42       Private   57576            9th             12   \n",
       "  \n",
       "              marital-status          occupation    relationship  \\\n",
       "  0            Never-married        Craft-repair         Husband   \n",
       "  1            Never-married               Sales         Husband   \n",
       "  2            Never-married        Adm-clerical       Own-child   \n",
       "  3                 Divorced                   ?         Husband   \n",
       "  4       Married-civ-spouse   Machine-op-inspct   Not-in-family   \n",
       "  ...                    ...                 ...             ...   \n",
       "  32556   Married-civ-spouse        Tech-support         Husband   \n",
       "  32557   Married-civ-spouse        Adm-clerical            Wife   \n",
       "  32558   Married-civ-spouse   Machine-op-inspct   Not-in-family   \n",
       "  32559   Married-civ-spouse     Exec-managerial       Unmarried   \n",
       "  32560        Never-married   Handlers-cleaners         Husband   \n",
       "  \n",
       "                        race      sex  capital-gain  capital-loss  \\\n",
       "  0                    White     Male            46             4   \n",
       "  1                    White   Female            57             0   \n",
       "  2                    White     Male             7             3   \n",
       "  3                    White     Male            13             0   \n",
       "  4                    White   Female            73             1   \n",
       "  ...                    ...      ...           ...           ...   \n",
       "  32556                White   Female            74             0   \n",
       "  32557                White   Female            38             0   \n",
       "  32558                White   Female            42             0   \n",
       "  32559                White   Female            76             4   \n",
       "  32560   Amer-Indian-Eskimo     Male            51             0   \n",
       "  \n",
       "         hours-per-week  native-country  income  \n",
       "  0                  40   United-States   <=50K  \n",
       "  1                  26   United-States   <=50K  \n",
       "  2                  40   United-States   <=50K  \n",
       "  3                  47   United-States   <=50K  \n",
       "  4                  52   United-States   <=50K  \n",
       "  ...               ...             ...     ...  \n",
       "  32556              40   United-States   <=50K  \n",
       "  32557              18   United-States    >50K  \n",
       "  32558              57           South   <=50K  \n",
       "  32559              40   United-States   <=50K  \n",
       "  32560              40   United-States   <=50K  \n",
       "  \n",
       "  [32561 rows x 15 columns],\n",
       "  'generator_model': <data_synthesizer.sdv.ctgan.ctgan_synthesizer_modified.SDVCTGAN_ at 0x7f8342c79880>},\n",
       " 'resemblance_evaluation_results': {'categorical_univariate': {'chi_test':                 chisquared_tests_p\n",
       "   workclass                 0.685735\n",
       "   education                 0.592877\n",
       "   marital-status            0.439165\n",
       "   occupation                0.075962\n",
       "   relationship              0.746129\n",
       "   race                      0.953195\n",
       "   sex                       0.296967\n",
       "   native-country            0.987672\n",
       "   income                    0.733345,\n",
       "   'jensen_shanon':                 KL_divergence_tests  JS_divergence\n",
       "   workclass                  0.014599       0.079200\n",
       "   education                  0.021062       0.089973\n",
       "   marital-status             0.020839       0.091790\n",
       "   occupation                 0.017707       0.081923\n",
       "   relationship               0.016834       0.079442\n",
       "   race                       0.040395       0.126972\n",
       "   sex                        0.005673       0.044885\n",
       "   native-country             0.039088       0.127040\n",
       "   income                     0.002376       0.029048,\n",
       "   'jensen_shanon_data_mean': KL_divergence_tests    0.019841\n",
       "   JS_divergence          0.083363\n",
       "   dtype: float64,\n",
       "   'mode_collapse_dict': {}},\n",
       "  'numerical_univariate': {'univariate_num_s':                 mann_whitney      wilcoxon     student_t  welchs_Ttest  \\\n",
       "   age             0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "   fnlwgt          2.741577e-18  4.609761e-20  4.619605e-12  4.619837e-12   \n",
       "   education-num   4.887050e-05  2.148456e-04  2.391714e-06  2.391748e-06   \n",
       "   capital-gain    0.000000e+00  0.000000e+00  1.840994e-37  1.980615e-37   \n",
       "   capital-loss    0.000000e+00  0.000000e+00  1.812109e-10  1.812297e-10   \n",
       "   hours-per-week  3.217820e-46  2.057725e-42  7.867412e-59  7.928083e-59   \n",
       "   \n",
       "                       ks_test_p  \n",
       "   age              0.000000e+00  \n",
       "   fnlwgt           2.833732e-60  \n",
       "   education-num    6.993236e-38  \n",
       "   capital-gain     0.000000e+00  \n",
       "   capital-loss     0.000000e+00  \n",
       "   hours-per-week  4.430068e-238  ,\n",
       "   'univariate_num_js':                 KL_divergence_tests  JS_divergence  cohen_s_d\n",
       "   age                        1.232985       0.184520   0.401673\n",
       "   fnlwgt                     0.000026       0.097825   0.054219\n",
       "   education-num              3.286990       0.129412   0.036973\n",
       "   capital-gain               0.005335       0.481723   0.100310\n",
       "   capital-loss               0.005522       0.116005   0.049982\n",
       "   hours-per-week             1.047821       0.194036   0.126877,\n",
       "   'univariate_num_js_data_mean': KL_divergence_tests    0.929780\n",
       "   JS_divergence          0.200587\n",
       "   cohen_s_d              0.128339\n",
       "   dtype: float64},\n",
       "  'categorical_multivariate': {'cramer_real':                 workclass  education  marital-status  occupation  \\\n",
       "   workclass        1.000000   0.099369        0.085061    0.399993   \n",
       "   education        0.099369   1.000000        0.091569    0.187334   \n",
       "   marital-status   0.085061   0.091569        1.000000    0.133213   \n",
       "   occupation       0.399993   0.187334        0.133213    1.000000   \n",
       "   relationship     0.098712   0.122654        0.487963    0.178626   \n",
       "   race             0.056280   0.074900        0.084219    0.080826   \n",
       "   sex              0.153670   0.095621        0.461827    0.424364   \n",
       "   native-country   0.045810   0.132637        0.073070    0.073121   \n",
       "   income           0.179208   0.368838        0.447404    0.351892   \n",
       "   \n",
       "                   relationship      race       sex  native-country    income  \n",
       "   workclass           0.098712  0.056280  0.153670        0.045810  0.179208  \n",
       "   education           0.122654  0.074900  0.095621        0.132637  0.368838  \n",
       "   marital-status      0.487963  0.084219  0.461827        0.073070  0.447404  \n",
       "   occupation          0.178626  0.080826  0.424364        0.073121  0.351892  \n",
       "   relationship        1.000000  0.098099  0.649000        0.085310  0.453585  \n",
       "   race                0.098099  1.000000  0.118115        0.409258  0.100812  \n",
       "   sex                 0.649000  0.118115  1.000000        0.067148  0.215980  \n",
       "   native-country      0.085310  0.409258  0.067148        1.000000  0.098705  \n",
       "   income              0.453585  0.100812  0.215980        0.098705  1.000000  ,\n",
       "   'cramer_synth':                 workclass  education  marital-status  occupation  \\\n",
       "   workclass        1.000000   0.021235        0.018087    0.022528   \n",
       "   education        0.021235   1.000000        0.025836    0.021028   \n",
       "   marital-status   0.018087   0.025836        1.000000    0.022611   \n",
       "   occupation       0.022528   0.021028        0.022611    1.000000   \n",
       "   relationship     0.017630   0.025109        0.016799    0.027721   \n",
       "   race             0.018848   0.025094        0.017767    0.025460   \n",
       "   sex              0.027378   0.045305        0.040140    0.032698   \n",
       "   native-country   0.040115   0.035496        0.036692    0.036087   \n",
       "   income           0.011289   0.035356        0.040014    0.028327   \n",
       "   \n",
       "                   relationship      race       sex  native-country    income  \n",
       "   workclass           0.017630  0.018848  0.027378        0.040115  0.011289  \n",
       "   education           0.025109  0.025094  0.045305        0.035496  0.035356  \n",
       "   marital-status      0.016799  0.017767  0.040140        0.036692  0.040014  \n",
       "   occupation          0.027721  0.025460  0.032698        0.036087  0.028327  \n",
       "   relationship        1.000000  0.015943  0.011236        0.038369  0.025051  \n",
       "   race                0.015943  1.000000  0.039108        0.035070  0.027737  \n",
       "   sex                 0.011236  0.039108  1.000000        0.031400  0.005998  \n",
       "   native-country      0.038369  0.035070  0.031400        1.000000  0.041574  \n",
       "   income              0.025051  0.027737  0.005998        0.041574  1.000000  ,\n",
       "   'diff_norm_cramer': 0.7048999999999999},\n",
       "  'numerical_multivariate': {'pearson_real':                      age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "   age             1.000000  0.076646       0.036527      0.077674      0.057775   \n",
       "   fnlwgt          0.076646  1.000000       0.043195      0.000432      0.010252   \n",
       "   education-num   0.036527  0.043195       1.000000      0.122630      0.079923   \n",
       "   capital-gain    0.077674  0.000432       0.122630      1.000000      0.031615   \n",
       "   capital-loss    0.057775  0.010252       0.079923      0.031615      1.000000   \n",
       "   hours-per-week  0.068756  0.018768       0.148123      0.078409      0.054256   \n",
       "   \n",
       "                   hours-per-week  \n",
       "   age                   0.068756  \n",
       "   fnlwgt                0.018768  \n",
       "   education-num         0.148123  \n",
       "   capital-gain          0.078409  \n",
       "   capital-loss          0.054256  \n",
       "   hours-per-week        1.000000  ,\n",
       "   'pearson_synth':                      age    fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "   age             1.000000  0.012817       0.003277      0.001128      0.004579   \n",
       "   fnlwgt          0.012817  1.000000       0.007206      0.007674      0.006315   \n",
       "   education-num   0.003277  0.007206       1.000000      0.000356      0.000735   \n",
       "   capital-gain    0.001128  0.007674       0.000356      1.000000      0.010531   \n",
       "   capital-loss    0.004579  0.006315       0.000735      0.010531      1.000000   \n",
       "   hours-per-week  0.013438  0.004517       0.009969      0.001002      0.005015   \n",
       "   \n",
       "                   hours-per-week  \n",
       "   age                   0.013438  \n",
       "   fnlwgt                0.004517  \n",
       "   education-num         0.009969  \n",
       "   capital-gain          0.001002  \n",
       "   capital-loss          0.005015  \n",
       "   hours-per-week        1.000000  ,\n",
       "   'pearson_norm_diff': 0.030999999999999694},\n",
       "  'categorical_numerical_multivariate': {'corr_ratio_real': {'corr':                 workclass  education  marital-status  occupation  \\\n",
       "    age              0.218365   0.229077        0.573546    0.186472   \n",
       "    fnlwgt           0.052620   0.067111        0.054406    0.055344   \n",
       "    education-num    0.197346   1.000000        0.115492    0.556586   \n",
       "    capital-gain     0.104268   0.197873        0.087206    0.119566   \n",
       "    capital-loss     0.046975   0.099203        0.081717    0.085112   \n",
       "    hours-per-week   0.228189   0.194284        0.250627    0.311444   \n",
       "    \n",
       "                    relationship      race       sex  native-country    income  \n",
       "    age                 0.474219  0.043588  0.088832        0.088367  0.234037  \n",
       "    fnlwgt              0.037277  0.140456  0.026858        0.158627  0.009463  \n",
       "    education-num       0.160911  0.109650  0.012280        0.276936  0.335154  \n",
       "    capital-gain        0.090418  0.023410  0.048480        0.035641  0.223329  \n",
       "    capital-loss        0.087701  0.026708  0.045567        0.053354  0.150526  \n",
       "    hours-per-week      0.310074  0.054680  0.229309        0.048591  0.229689  ,\n",
       "    'ax': <Axes: >},\n",
       "   'corr_ratio_synth': {'corr':                 workclass  education  marital-status  occupation  \\\n",
       "    age              0.017941   0.020332        0.013357    0.019960   \n",
       "    fnlwgt           0.021606   0.023499        0.013413    0.025683   \n",
       "    education-num    0.014873   0.020232        0.022792    0.018795   \n",
       "    capital-gain     0.020407   0.025397        0.018984    0.016911   \n",
       "    capital-loss     0.019211   0.020720        0.010499    0.020224   \n",
       "    hours-per-week   0.025806   0.016889        0.008765    0.025177   \n",
       "    \n",
       "                    relationship      race       sex  native-country    income  \n",
       "    age                 0.014110  0.020925  0.016572        0.037551  0.030107  \n",
       "    fnlwgt              0.018858  0.007461  0.008456        0.043012  0.003846  \n",
       "    education-num       0.017658  0.005992  0.015733        0.030525  0.018107  \n",
       "    capital-gain        0.009679  0.005823  0.002546        0.038670  0.004150  \n",
       "    capital-loss        0.011473  0.016424  0.006636        0.037014  0.010992  \n",
       "    hours-per-week      0.010056  0.015682  0.012023        0.031045  0.008622  ,\n",
       "    'ax': <Axes: >},\n",
       "   'diff_norm_corr_ratio': 1.6022}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0499984644206259"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_synthesizer.privacy_sampling import get_epsilon\n",
    "\n",
    "\n",
    "get_epsilon(df_real_adult_train, synth, cat_list_adult, num_list_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SEX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SEX'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data_to_evaluate \u001b[38;5;241m=\u001b[39m DataLoader(dataset \u001b[38;5;241m=\u001b[39m df_real_credit_card_train)\u001b[38;5;241m.\u001b[39mget_dataframe(cat_list_credit_card)\n\u001b[0;32m----> 2\u001b[0m synth_data_to_evaluate \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msynth\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_list_credit_card\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m uni_evaluators \u001b[38;5;241m=\u001b[39m UnivariateEvaluator(train_data_to_evaluate, synth_data_to_evaluate)\n\u001b[1;32m      5\u001b[0m uni_evaluators\u001b[38;5;241m.\u001b[39mevaluate_mode_collapse_values()\n",
      "File \u001b[0;32m~/tabularDataSynth2/tabularDataSynth/src/data_loader/data_loader.py:17\u001b[0m, in \u001b[0;36mDataLoader.get_dataframe\u001b[0;34m(self, categorical_cols, category_type, drop_identation, sep, convert_float)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, sep \u001b[38;5;241m=\u001b[39m sep)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m categorical_cols :\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[column] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(category_type)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(drop_identation) :\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/sdv_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SEX'"
     ]
    }
   ],
   "source": [
    "train_data_to_evaluate = DataLoader(dataset = df_real_credit_card_train).get_dataframe(cat_list_credit_card)\n",
    "synth_data_to_evaluate = DataLoader(dataset = synth).get_dataframe(cat_list_credit_card)\n",
    "\n",
    "uni_evaluators = UnivariateEvaluator(train_data_to_evaluate, synth_data_to_evaluate)\n",
    "uni_evaluators.evaluate_mode_collapse_values()\n",
    "mode_collapse = uni_evaluators.get_mode_collapse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '3', '4', '5', '6']\n",
      "['0', '3']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mask = pd.Series([False] * len(df_real_credit_card_train))\n",
    "\n",
    "for feature, values in mode_collapse.items():\n",
    "    print(values)\n",
    "    mask |= df_real_credit_card_train[feature].isin(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LIMIT_BAL SEX EDUCATION MARRIAGE  AGE PAY_0 PAY_2 PAY_3 PAY_4 PAY_5  \\\n",
      "2       180000.0   2         5        1   44     0     0    -1    -1    -1   \n",
      "5        20000.0   1         3        2   32     1     2     0     0     0   \n",
      "9       360000.0   2         3        1   43    -2    -2    -2    -2    -2   \n",
      "10      220000.0   2         2        2   38    -1    -1    -1    -1    -1   \n",
      "12      100000.0   1         1        2   27    -1     2     0     0     0   \n",
      "...          ...  ..       ...      ...  ...   ...   ...   ...   ...   ...   \n",
      "23992   280000.0   2         1        1   32     1    -2    -1     0     0   \n",
      "23993   160000.0   2         2        1   42     0     0     0     0     0   \n",
      "23996   200000.0   1         1        2   37     2     2     2     2     2   \n",
      "23998    70000.0   2         2        2   25     0     0     0     0     2   \n",
      "23999   160000.0   2         2        1   36    -2    -2    -2    -2    -2   \n",
      "\n",
      "       ... BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
      "2      ...       0.0     6881.0    10340.0       0.0     850.0       0.0   \n",
      "5      ...   19588.0    20037.0    19880.0       0.0    1302.0     685.0   \n",
      "9      ...   15584.0     3195.0     4261.0     805.0    1071.0   15604.0   \n",
      "10     ...    1621.0     8522.0     4149.0    5575.0    4716.0    1632.0   \n",
      "12     ...    6746.0     7889.0        0.0       0.0    1000.0    2000.0   \n",
      "...    ...       ...        ...        ...       ...       ...       ...   \n",
      "23992  ...    3508.0     -200.0     -200.0       0.0    3508.0       0.0   \n",
      "23993  ...  119529.0   122059.0   111378.0    8450.0    5289.0    4022.0   \n",
      "23996  ...  164182.0   169029.0   172084.0   13500.0    6000.0       0.0   \n",
      "23998  ...   35122.0    28633.0    28039.0    3000.0    2000.0    4500.0   \n",
      "23999  ...    2935.0     1603.0    14129.0       0.0    3660.0    3135.0   \n",
      "\n",
      "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
      "2        6881.0   10340.0     182.0                           0  \n",
      "5         748.0     697.0     690.0                           0  \n",
      "9        3195.0    4269.0    3525.0                           0  \n",
      "10       8559.0    4164.0   10626.0                           1  \n",
      "12       3323.0       0.0       0.0                           1  \n",
      "...         ...       ...       ...                         ...  \n",
      "23992       0.0       0.0       0.0                           1  \n",
      "23993    4195.0    3986.0    3958.0                           1  \n",
      "23996    7500.0    6000.0    4000.0                           1  \n",
      "23998    1200.0       0.0    1200.0                           1  \n",
      "23999    1650.0   14200.0    1500.0                           1  \n",
      "\n",
      "[10436 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_D = df_real_credit_card_train[mask]\n",
    "print(filtered_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6881.0</td>\n",
       "      <td>10340.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6881.0</td>\n",
       "      <td>10340.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19588.0</td>\n",
       "      <td>20037.0</td>\n",
       "      <td>19880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>15584.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>4261.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>1071.0</td>\n",
       "      <td>15604.0</td>\n",
       "      <td>3195.0</td>\n",
       "      <td>4269.0</td>\n",
       "      <td>3525.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>8522.0</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>5575.0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>8559.0</td>\n",
       "      <td>4164.0</td>\n",
       "      <td>10626.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6746.0</td>\n",
       "      <td>7889.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10431</th>\n",
       "      <td>23992</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3508.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10432</th>\n",
       "      <td>23993</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119529.0</td>\n",
       "      <td>122059.0</td>\n",
       "      <td>111378.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>5289.0</td>\n",
       "      <td>4022.0</td>\n",
       "      <td>4195.0</td>\n",
       "      <td>3986.0</td>\n",
       "      <td>3958.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>23996</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>164182.0</td>\n",
       "      <td>169029.0</td>\n",
       "      <td>172084.0</td>\n",
       "      <td>13500.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10434</th>\n",
       "      <td>23998</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>35122.0</td>\n",
       "      <td>28633.0</td>\n",
       "      <td>28039.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10435</th>\n",
       "      <td>23999</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>2935.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>14129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>3135.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10436 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  LIMIT_BAL SEX EDUCATION MARRIAGE  AGE PAY_0 PAY_2 PAY_3 PAY_4  \\\n",
       "0          2   180000.0   2         5        1   44     0     0    -1    -1   \n",
       "1          5    20000.0   1         3        2   32     1     2     0     0   \n",
       "2          9   360000.0   2         3        1   43    -2    -2    -2    -2   \n",
       "3         10   220000.0   2         2        2   38    -1    -1    -1    -1   \n",
       "4         12   100000.0   1         1        2   27    -1     2     0     0   \n",
       "...      ...        ...  ..       ...      ...  ...   ...   ...   ...   ...   \n",
       "10431  23992   280000.0   2         1        1   32     1    -2    -1     0   \n",
       "10432  23993   160000.0   2         2        1   42     0     0     0     0   \n",
       "10433  23996   200000.0   1         1        2   37     2     2     2     2   \n",
       "10434  23998    70000.0   2         2        2   25     0     0     0     0   \n",
       "10435  23999   160000.0   2         2        1   36    -2    -2    -2    -2   \n",
       "\n",
       "       ... BILL_AMT4 BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      ...       0.0    6881.0    10340.0       0.0     850.0       0.0   \n",
       "1      ...   19588.0   20037.0    19880.0       0.0    1302.0     685.0   \n",
       "2      ...   15584.0    3195.0     4261.0     805.0    1071.0   15604.0   \n",
       "3      ...    1621.0    8522.0     4149.0    5575.0    4716.0    1632.0   \n",
       "4      ...    6746.0    7889.0        0.0       0.0    1000.0    2000.0   \n",
       "...    ...       ...       ...        ...       ...       ...       ...   \n",
       "10431  ...    3508.0    -200.0     -200.0       0.0    3508.0       0.0   \n",
       "10432  ...  119529.0  122059.0   111378.0    8450.0    5289.0    4022.0   \n",
       "10433  ...  164182.0  169029.0   172084.0   13500.0    6000.0       0.0   \n",
       "10434  ...   35122.0   28633.0    28039.0    3000.0    2000.0    4500.0   \n",
       "10435  ...    2935.0    1603.0    14129.0       0.0    3660.0    3135.0   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0        6881.0   10340.0     182.0                           0  \n",
       "1         748.0     697.0     690.0                           0  \n",
       "2        3195.0    4269.0    3525.0                           0  \n",
       "3        8559.0    4164.0   10626.0                           1  \n",
       "4        3323.0       0.0       0.0                           1  \n",
       "...         ...       ...       ...                         ...  \n",
       "10431       0.0       0.0       0.0                           1  \n",
       "10432    4195.0    3986.0    3958.0                           1  \n",
       "10433    7500.0    6000.0    4000.0                           1  \n",
       "10434    1200.0       0.0    1200.0                           1  \n",
       "10435    1650.0   14200.0    1500.0                           1  \n",
       "\n",
       "[10436 rows x 25 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_D.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Reconstruct Loss:  27.0434,KLD Loss:  4.7940\n",
      "Epoch 2, Reconstruct Loss:  30.1614,KLD Loss:  5.2331\n",
      "Epoch 3, Reconstruct Loss:  36.4279,KLD Loss:  5.5586\n",
      "Epoch 4, Reconstruct Loss:  46.8723,KLD Loss:  4.6960\n",
      "Epoch 5, Reconstruct Loss:  55.3024,KLD Loss:  2.0771\n",
      "['0', '3', '4', '5', '6']\n",
      "['0', '3']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['1', '3', '4', '5', '6', '7', '8']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['2', '3', '4', '5', '6', '7', '8']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "ctgan.fit_with_only_rare(filtered_D)\n",
    "ctgan.reset_sampling()\n",
    "synth_data_new = ctgan.sample(len(df_real_credit_card_train))\n",
    "\n",
    "mask_ = pd.Series([False] * len(df_real_credit_card_train))\n",
    "\n",
    "for feature, values in mode_collapse.items():\n",
    "    print(values)\n",
    "    mask_ |= synth_data_new[feature].isin(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118241.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>23769.0</td>\n",
       "      <td>17619.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2362.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3955.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160208.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3570.0</td>\n",
       "      <td>21745.0</td>\n",
       "      <td>32241.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>2588.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126621.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>21458.0</td>\n",
       "      <td>13619.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>1647.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142494.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-472.0</td>\n",
       "      <td>10138.0</td>\n",
       "      <td>17305.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2511.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121203.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>33551.0</td>\n",
       "      <td>10505.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>132362.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>729.0</td>\n",
       "      <td>17296.0</td>\n",
       "      <td>8899.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2442.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3043.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>145460.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1019.0</td>\n",
       "      <td>14361.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>154833.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3788.0</td>\n",
       "      <td>22496.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2726.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>152616.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1257.0</td>\n",
       "      <td>26667.0</td>\n",
       "      <td>6083.0</td>\n",
       "      <td>2482.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2433.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>158552.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-561.0</td>\n",
       "      <td>20837.0</td>\n",
       "      <td>17339.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL SEX EDUCATION MARRIAGE  AGE PAY_0 PAY_2 PAY_3 PAY_4 PAY_5  \\\n",
       "0       118241.0   2         2        1   35     0     2     2     0     0   \n",
       "1       160208.0   2         2        1   33     0     2     2     0     0   \n",
       "2       126621.0   2         2        1   35     0     2     2     0     0   \n",
       "3       142494.0   2         2        1   34     0     2     2     0     0   \n",
       "4       121203.0   2         2        1   31     0     2     2     0     0   \n",
       "...          ...  ..       ...      ...  ...   ...   ...   ...   ...   ...   \n",
       "23995   132362.0   2         2        1   33     0     2     2     0     0   \n",
       "23996   145460.0   2         2        1   38     0     2     2     0     0   \n",
       "23997   154833.0   2         2        1   38     0     2     2     0     0   \n",
       "23998   152616.0   2         2        1   33     0     2     2     0     0   \n",
       "23999   158552.0   2         2        1   39     0     2     2     0     0   \n",
       "\n",
       "       ... BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      ...    1914.0    23769.0    17619.0     413.0     586.0    1291.0   \n",
       "1      ...   -3570.0    21745.0    32241.0    1296.0    2483.0     455.0   \n",
       "2      ...      71.0    21458.0    13619.0    1569.0    1789.0     933.0   \n",
       "3      ...    -472.0    10138.0    17305.0    2310.0     403.0       0.0   \n",
       "4      ...     -20.0    33551.0    10505.0    2247.0    1603.0     857.0   \n",
       "...    ...       ...        ...        ...       ...       ...       ...   \n",
       "23995  ...     729.0    17296.0     8899.0       0.0       0.0     413.0   \n",
       "23996  ...   -1019.0    14361.0     6516.0     138.0    1451.0     609.0   \n",
       "23997  ...    3788.0    22496.0      870.0       0.0    1521.0       0.0   \n",
       "23998  ...   -1257.0    26667.0     6083.0    2482.0    1884.0     668.0   \n",
       "23999  ...    -561.0    20837.0    17339.0       0.0     431.0     310.0   \n",
       "\n",
       "       PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0        2362.0       0.0    3955.0                           0  \n",
       "1        1664.0     306.0    2588.0                           0  \n",
       "2        1647.0       0.0     246.0                           0  \n",
       "3        2511.0     412.0    2795.0                           0  \n",
       "4        1658.0       0.0    3165.0                           0  \n",
       "...         ...       ...       ...                         ...  \n",
       "23995    2442.0       0.0    3043.0                           0  \n",
       "23996    3081.0     340.0    1074.0                           0  \n",
       "23997     589.0      24.0    2726.0                           0  \n",
       "23998     684.0       0.0    2433.0                           0  \n",
       "23999     834.0     286.0     851.0                           0  \n",
       "\n",
       "[24000 rows x 24 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_D_ = synth_data_new[mask_]\n",
    "filtered_D_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_to_evaluate = DataLoader(dataset = df_real_credit_card_train).get_dataframe(cat_list_credit_card)\n",
    "synth_data_to_evaluate_new = DataLoader(dataset = df_combined).get_dataframe(cat_list_credit_card)\n",
    "\n",
    "uni_evaluators = UnivariateEvaluator(train_data_to_evaluate, synth_data_to_evaluate_new)\n",
    "uni_evaluators.evaluate_mode_collapse_values()\n",
    "mode_collapse_ = uni_evaluators.get_mode_collapse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': ['0', '3', '4', '5', '6'],\n",
       " 'MARRIAGE': ['0', '3'],\n",
       " 'PAY_0': ['2', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_2': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_3': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_4': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_5': ['2', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_6': ['2', '3', '4', '5', '6', '7', '8'],\n",
       " 'default.payment.next.month': ['1']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EDUCATION': ['0', '3', '4', '5', '6'],\n",
       " 'MARRIAGE': ['0', '3'],\n",
       " 'PAY_0': ['2', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_2': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_3': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_4': ['1', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_5': ['2', '3', '4', '5', '6', '7', '8'],\n",
       " 'PAY_6': ['2', '3', '4', '5', '6', '7', '8']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_collapse_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = {}\n",
    "for column in synth.columns:\n",
    "    most_common_value = synth[column].value_counts().idxmax()\n",
    "    most_frequent[column] = most_common_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = synth.copy()\n",
    "most_common_value = most_frequent['EDUCATION']\n",
    "most_common_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(synth_data_new['EDUCATION'] == '0').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION  :  ['0', '3', '4', '5', '6']\n",
      "MARRIAGE  :  ['0', '3']\n",
      "PAY_0  :  ['2', '3', '4', '5', '6', '7', '8']\n",
      "PAY_2  :  ['1', '3', '4', '5', '6', '7', '8']\n",
      "PAY_3  :  ['1', '3', '4', '5', '6', '7', '8']\n",
      "PAY_4  :  ['1', '3', '4', '5', '6', '7', '8']\n",
      "PAY_5  :  ['2', '3', '4', '5', '6', '7', '8']\n",
      "PAY_6  :  ['2', '3', '4', '5', '6', '7', '8']\n",
      "default.payment.next.month  :  ['1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_combined = synth.copy()\n",
    "for feature, values in mode_collapse.items():\n",
    "    print(feature, ' : ', values)\n",
    "    most_common_value = most_frequent[feature]\n",
    "    for value in values :\n",
    "        filter = (synth_data_to_evaluate_new[feature] == value)\n",
    "        filtered_df = synth_data_to_evaluate_new[filter]\n",
    "        ten_sampled_df = filtered_df.sample(n=10, random_state=42) if len(filtered_df) >= 10 else filtered_df\n",
    "        df_combined = pd.concat([df_combined, ten_sampled_df], ignore_index=True)\n",
    "\n",
    "        filter_most = (df_combined[feature] == most_common_value)\n",
    "        # filtered_df_most = df_combined[filter]\n",
    "        random_index = df_combined[filter_most].sample(len(ten_sampled_df)).index\n",
    "        df_combined = df_combined.drop(random_index)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy anonymeter evaluation in progress.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 21 failed queries out of 500. Check DEBUG messages for more details.\n",
      "Found 68 failed queries out of 500. Check DEBUG messages for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "pipeline_builder = PipelineBuilder(df_real_credit_card_train, cat_list_credit_card, num_list_credit_card)\n",
    "# pipeline_builder.add_ressemblance_evaluation_task(df_real_credit_card_test, df_real_credit_card_ctgan_fourth )\n",
    "# pipeline_builder.add_utility_evaluation_task(df_real_credit_card_test, [ClassifierType.XGBOOST, ClassifierType.CART], df_real_credit_card_ctgan_fourth)\n",
    "qai_columns = ['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE']\n",
    "risk_column = ['PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6','default.payment.next.month']\n",
    "pipeline_builder.add_privacy_anonymeter_evaluation_task(df_real_credit_card_test, df_real_credit_card_ctgan_fourth )\n",
    "\n",
    "pipeline = pipeline_builder.build()\n",
    "synth = pipeline_builder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical_univariate\n",
      "numerical_univariate\n",
      "categorical_multivariate\n",
      "numerical_multivariate\n",
      "categorical_numerical_multivariate\n"
     ]
    }
   ],
   "source": [
    "for key in synth['resemblance_evaluation_results'] :\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'privacy_anonymeter_evaluation_results': {'singling_univariate': AnonymeterResults(attacks_numbers=500, attacks_succeeded=60, privacy_risk_original=0.12289724937538986, privacy_risk_control=0.1837185152398014, privacy_risk_naive=0.03556819133600645, specific_privacy=0.0),\n",
       "  'singling_multivariate': AnonymeterResults(attacks_numbers=500, attacks_succeeded=57, privacy_risk_original=0.11694299541815917, privacy_risk_control=0.06867004284042351, privacy_risk_naive=0.04152244529323714, specific_privacy=0.051832277279001394),\n",
       "  'linkability_attacks': AnonymeterResults(attacks_numbers=2000, attacks_succeeded=2000, privacy_risk_original=0.0343943025567045, privacy_risk_control=0.0249125145058764, privacy_risk_naive=0.003952772498782709, specific_privacy=0.00972403829593118)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
